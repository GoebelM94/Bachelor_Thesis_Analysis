{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fffbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8833f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Excel file with data\n",
    "xlx = '../data/Coding_JSIS_MISQ_V5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f859123d",
   "metadata": {},
   "source": [
    "# exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11ad71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Excel file to dataframe\n",
    "\n",
    "df = pd.read_excel(xlx, header=0)\n",
    "\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc66fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exploratory CS:  32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Autor/en</th>\n",
       "      <th>Use of CSR stated</th>\n",
       "      <th>Use of CSR stated DETAIL</th>\n",
       "      <th>CSR used in keywords</th>\n",
       "      <th>CSR used in keywords DETAIL</th>\n",
       "      <th>...</th>\n",
       "      <th>Comparison with similar literature (only exploratory) DETAIL</th>\n",
       "      <th>Key case study characteristics summarized</th>\n",
       "      <th>Key case study characteristics summarized  DETAIL</th>\n",
       "      <th>Methodological literature cited</th>\n",
       "      <th>Methodological literature cited DETAIL</th>\n",
       "      <th>Other case studies cited</th>\n",
       "      <th>Other case studies cited DETAIL</th>\n",
       "      <th>Online-Appendix</th>\n",
       "      <th>Online-Appendix DETAIL</th>\n",
       "      <th>Classification in terms of methodological rigor (descending: ++, +, o, -)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>A strategic activity model of Enterprise Syste...</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Jenny Leonard, Helen Higson</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.1. Case study design + A case study approach...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>This contributes to understanding some aspects...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yin, R., 2003. Case Study Research: Design and...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>Forced coopetition in IT multi-sourcing</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Martin Wiener, Carol Saunders</td>\n",
       "      <td>yes</td>\n",
       "      <td>To develop a deeper understanding of this mode...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>Turning to the critical factors that enabled G...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yin, R., 1994. Case Study Research: Design and...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Journal                                              Titel  Jahr  Volume  \\\n",
       "0    JSIS  A strategic activity model of Enterprise Syste...  2014      23   \n",
       "1    JSIS            Forced coopetition in IT multi-sourcing  2014      23   \n",
       "\n",
       "   Issue                       Autor/en Use of CSR stated  \\\n",
       "0      1    Jenny Leonard, Helen Higson               yes   \n",
       "1      3  Martin Wiener, Carol Saunders               yes   \n",
       "\n",
       "                            Use of CSR stated DETAIL CSR used in keywords  \\\n",
       "0  3.1. Case study design + A case study approach...                   no   \n",
       "1  To develop a deeper understanding of this mode...                   no   \n",
       "\n",
       "  CSR used in keywords DETAIL  ...  \\\n",
       "0                           -  ...   \n",
       "1                           -  ...   \n",
       "\n",
       "  Comparison with similar literature (only exploratory) DETAIL  \\\n",
       "0  This contributes to understanding some aspects...             \n",
       "1  Turning to the critical factors that enabled G...             \n",
       "\n",
       "  Key case study characteristics summarized   \\\n",
       "0                                         no   \n",
       "1                                         no   \n",
       "\n",
       "  Key case study characteristics summarized  DETAIL  \\\n",
       "0                                                 -   \n",
       "1                                                 -   \n",
       "\n",
       "  Methodological literature cited  \\\n",
       "0                             yes   \n",
       "1                             yes   \n",
       "\n",
       "              Methodological literature cited DETAIL Other case studies cited  \\\n",
       "0  Yin, R., 2003. Case Study Research: Design and...                       no   \n",
       "1  Yin, R., 1994. Case Study Research: Design and...                       no   \n",
       "\n",
       "  Other case studies cited DETAIL Online-Appendix Online-Appendix DETAIL  \\\n",
       "0                               -              no                      -   \n",
       "1                               -              no                      -   \n",
       "\n",
       "  Classification in terms of methodological rigor (descending: ++, +, o, -)  \n",
       "0                                                  -                         \n",
       "1                                                  +                         \n",
       "\n",
       "[2 rows x 187 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe for exploratory research purpose\n",
    "\n",
    "df = df.loc[df['Research purpose'] == 'exploratory']\n",
    "purpose_len = len(df)\n",
    "print('Number exploratory CS: ', purpose_len)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2019b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number single cases:  22\n",
      "Number multiple cases:  10\n"
     ]
    }
   ],
   "source": [
    "# dataframes for single and multiple CS\n",
    "\n",
    "# 1. single CS\n",
    "df_single = df.loc[df['Number of cases'] == 1]\n",
    "single_len = len(df_single)\n",
    "print('Number single cases: ', single_len)\n",
    "#df_single.head()\n",
    "\n",
    "#2. multiple CS\n",
    "df_multiple = df.loc[df['Number of cases'] > 1]\n",
    "multiple_len = len(df_multiple)\n",
    "print('Number multiple cases: ', multiple_len)\n",
    "#df_multiple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9e4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number interview cases:  29\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including interviews\n",
    "\n",
    "df_interv = df.loc[df['Interviews '] == 'yes']\n",
    "interv_len = len(df_interv)\n",
    "print('Number interview cases: ', interv_len)\n",
    "#df_interv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333fe09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Questionnaires cases:  0\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including questionnaires\n",
    "\n",
    "df_quest = df.loc[df['Questionnaires'] == 'yes']\n",
    "quest_len = len(df_quest)\n",
    "print('Number Questionnaires cases: ', quest_len)\n",
    "#df_quest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a288587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number coding cases:  28\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including coding\n",
    "\n",
    "df_code = df.loc[df['Coding of raw data'] == 'yes']\n",
    "code_len = len(df_code)\n",
    "print('Number coding cases: ', code_len)\n",
    "#df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc743d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f11af1",
   "metadata": {},
   "source": [
    "_**Research Design**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b63df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting CSR:  23  =>  0.71875\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting CSR\n",
    "\n",
    "rationale_csr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for conducting CSR'].iloc[i] == 'yes':\n",
    "        rationale_csr_all += 1\n",
    "\n",
    "print('Rationale for conducting CSR: ', rationale_csr_all, ' => ', rationale_csr_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a42a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research question all:  23  =>  0.71875\n",
      "goal with interrogative all:  5  =>  0.15625\n",
      "goal without interrogative all:  4  =>  0.125\n",
      "\n",
      "Research question or goal with interrogative all:  28  =>  0.875\n"
     ]
    }
   ],
   "source": [
    "# Clear research questions \n",
    "\n",
    "question_all = 0\n",
    "w_interr_all = 0\n",
    "wo_interr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Clear research questions '].iloc[i] == 'yes':\n",
    "        question_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal with interrogative':\n",
    "        w_interr_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal without interrogative':\n",
    "        wo_interr_all += 1\n",
    "\n",
    "print('Research question all: ', question_all, ' => ', question_all/purpose_len)\n",
    "print('goal with interrogative all: ', w_interr_all, ' => ', w_interr_all/purpose_len)\n",
    "print('goal without interrogative all: ', wo_interr_all, ' => ', wo_interr_all/purpose_len)\n",
    "print('')\n",
    "print('Research question or goal with interrogative all: ', question_all+w_interr_all, ' => ',  (question_all+w_interr_all)/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c1c630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['how, how', '-', 'how', 'what, how', 'how, why', 'how, what',\n",
       "       'what, to what, what', 'how, to what', 'what', 'does, how'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of research questions \n",
    "\n",
    "types_rq = df['Types of research questions '].unique()\n",
    "types_rq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "527a4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori specification of constructs (only exploratory):  28  =>  0.875\n"
     ]
    }
   ],
   "source": [
    "# A priori specification of constructs (only exploratory)\n",
    "\n",
    "a_priori_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['A priori specification of constructs (only exploratory)'].iloc[i] == 'yes':\n",
    "            a_priori_all += 1\n",
    "\n",
    "    print('A priori specification of constructs (only exploratory): ', a_priori_all, ' => ', a_priori_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec10476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean theoretical slate (only exploratory):  15  =>  0.46875\n"
     ]
    }
   ],
   "source": [
    "# Clean theoretical slate (only exploratory)\n",
    "\n",
    "cl_theor_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['Clean theoretical slate (only exploratory)'].iloc[i] == 'yes':\n",
    "            cl_theor_all += 1\n",
    "\n",
    "    print('Clean theoretical slate (only exploratory): ', cl_theor_all, ' => ', cl_theor_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55e8de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case acquisition strategy:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Case acquisition strategy\n",
    "\n",
    "acquisition_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case acquisition strategy'].iloc[i] == 'yes':\n",
    "        acquisition_all += 1\n",
    "\n",
    "print('Case acquisition strategy: ', acquisition_all, ' => ', acquisition_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082a3b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1, 22, 20,  3,  4], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cases\n",
    "\n",
    "number_cases = df['Number of cases'].unique()\n",
    "number_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0930a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting a single/multiple case study:  20  =>  0.625\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting a single/multiple case study\n",
    "\n",
    "rationale_single_multiple_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for conducting a single/multiple case study'].iloc[i] == 'yes':\n",
    "        rationale_single_multiple_all += 1\n",
    "\n",
    "print('Rationale for conducting a single/multiple case study: ', rationale_single_multiple_all, ' => ', rationale_single_multiple_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed72db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:  0  =>  0.0\n",
      "extreme:  4  =>  0.18181818181818182\n",
      "intensity:  1  =>  0.045454545454545456\n",
      "revelatory:  5  =>  0.22727272727272727\n",
      "theoretical:  1  =>  0.045454545454545456\n",
      "typical:  0  =>  0.0\n",
      "unique:  2  =>  0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Nature of single-case design\n",
    "\n",
    "criterion_all = 0\n",
    "extreme_all = 0\n",
    "intensity_all = 0\n",
    "revelatory_all = 0\n",
    "theoretical_all = 0\n",
    "typical_all = 0\n",
    "unique_all = 0\n",
    "\n",
    "for i in range(0, single_len):\n",
    "    if df_single['Nature of single-case design'].iloc[i] == 'criterion':\n",
    "        criterion_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'extreme':\n",
    "        extreme_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'intensity':\n",
    "        intensity_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'revelatory':\n",
    "        revelatory_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'theoretical':\n",
    "        theoretical_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'typical':\n",
    "        typical_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'unique':\n",
    "        unique_all += 1    \n",
    "\n",
    "print('criterion: ', criterion_all, ' => ', criterion_all/single_len)\n",
    "print('extreme: ', extreme_all, ' => ', extreme_all/single_len)\n",
    "print('intensity: ', intensity_all, ' => ', intensity_all/single_len)\n",
    "print('revelatory: ', revelatory_all, ' => ', revelatory_all/single_len)\n",
    "print('theoretical: ', theoretical_all, ' => ', theoretical_all/single_len)\n",
    "print('typical: ', typical_all, ' => ', typical_all/single_len)\n",
    "print('unique: ', unique_all, ' => ', unique_all/single_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5343de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literal:  5  =>  0.5\n",
      "theoretical:  4  =>  0.4\n"
     ]
    }
   ],
   "source": [
    "# Replication logic in multiple-case design\n",
    "\n",
    "literal_all = 0\n",
    "theoretical_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Replication logic in multiple-case design'].iloc[i] == 'literal':\n",
    "        literal_all += 1\n",
    "    elif df_multiple['Replication logic in multiple-case design'].iloc[i] == 'theoretical':\n",
    "        theoretical_all += 1\n",
    "\n",
    "print('literal: ', literal_all, ' => ', literal_all/multiple_len)\n",
    "print('theoretical: ', theoretical_all, ' => ', theoretical_all/multiple_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922a9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s reasonably chosen:  26  =>  0.8125\n"
     ]
    }
   ],
   "source": [
    "# Case/s reasonably chosen\n",
    "\n",
    "cases_reason_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case/s reasonably chosen'].iloc[i] == 'yes':\n",
    "        cases_reason_all += 1\n",
    "\n",
    "print('Case/s reasonably chosen: ', cases_reason_all, ' => ', cases_reason_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640e4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s defined:  32  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Case/s defined\n",
    "\n",
    "cases_def_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case/s defined'].iloc[i] == 'yes':\n",
    "        cases_def_all += 1\n",
    "\n",
    "print('Case/s defined: ', cases_def_all, ' => ', cases_def_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7616fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case/s\n",
    "\n",
    "cases = df['Case/s'].unique()\n",
    "#cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fba81e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit of analysis stated:  8  =>  0.25\n"
     ]
    }
   ],
   "source": [
    "# Unit of analysis stated\n",
    "\n",
    "uoa_stated_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Unit of analysis stated'].iloc[i] == 'yes':\n",
    "        uoa_stated_all += 1\n",
    "\n",
    "print('Unit of analysis stated: ', uoa_stated_all, ' => ', uoa_stated_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af4ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit of analysis\n",
    "\n",
    "uoa = df['Unit of analysis'].unique()\n",
    "#uoa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45526542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for choosing the unit of analysis:  13  =>  0.40625\n"
     ]
    }
   ],
   "source": [
    "# Rationale for choosing the unit of analysis\n",
    "\n",
    "rationale_uoa_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for choosing the unit of analysis'].iloc[i] == 'yes':\n",
    "        rationale_uoa_all += 1\n",
    "\n",
    "print('Rationale for choosing the unit of analysis: ', rationale_uoa_all, ' => ', rationale_uoa_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef35460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case design:  27  =>  0.84375\n",
      "Case design:  5  =>  0.15625\n"
     ]
    }
   ],
   "source": [
    "# Case design\n",
    "\n",
    "embedded_all = 0\n",
    "holistic_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case design'].iloc[i] == 'embedded':\n",
    "        embedded_all += 1\n",
    "    elif df['Case design'].iloc[i] == 'holistic':\n",
    "        holistic_all += 1\n",
    "\n",
    "print('Case design: ', embedded_all, ' => ', embedded_all/purpose_len)\n",
    "print('Case design: ', holistic_all, ' => ', holistic_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa49031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale research site:  27  =>  0.84375\n"
     ]
    }
   ],
   "source": [
    "# Rationale research site\n",
    "\n",
    "rationale_site_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale research site'].iloc[i] == 'yes' or df['Rationale research site'].iloc[i] == 'yes, see case selection':\n",
    "        rationale_site_all += 1\n",
    "\n",
    "print('Rationale research site: ', rationale_site_all, ' => ', rationale_site_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "505226f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  22  =>  0.6875\n",
      "rough:  7  =>  0.21875\n"
     ]
    }
   ],
   "source": [
    "# Detail research site\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Detail research site'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Detail research site'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bc46ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on-site:  26  =>  0.8125\n",
      "off-site:  3  =>  0.09375\n",
      "both:  3  =>  0.09375\n"
     ]
    }
   ],
   "source": [
    "# Research site\n",
    "\n",
    "on_all = 0\n",
    "off_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Research site'].iloc[i] == 'on-site':\n",
    "        on_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'off-site':\n",
    "        off_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'on-site, off-side':\n",
    "        both_all += 1\n",
    "\n",
    "print('on-site: ', on_all, ' => ', on_all/purpose_len)\n",
    "print('off-site: ', off_all, ' => ', off_all/purpose_len)\n",
    "print('both: ', both_all, ' => ', both_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07e08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of a pilot case:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use of a pilot case\n",
    "\n",
    "pilot_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Use of a pilot case'].iloc[i] == 'yes':\n",
    "        pilot_all += 1\n",
    "\n",
    "print('Use of a pilot case: ', pilot_all, ' => ', pilot_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78178137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site description:  22  =>  0.6875\n"
     ]
    }
   ],
   "source": [
    "# Site description\n",
    "\n",
    "site_descr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Site description'].iloc[i] != 'not specified':\n",
    "        site_descr_all += 1\n",
    "\n",
    "print('Site description: ', site_descr_all, ' => ', site_descr_all/purpose_len)\n",
    "\n",
    "site_descr_unique = df['Site description'].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f35814e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case period:  17  =>  0.53125\n"
     ]
    }
   ],
   "source": [
    "# Case period\n",
    "\n",
    "period_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case period '].iloc[i] != 'not specified':\n",
    "        period_all += 1\n",
    "\n",
    "print('Case period: ', period_all, ' => ', period_all/purpose_len)\n",
    "\n",
    "site_descr_unique = df['Case period '].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d16517a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal design:  10  =>  0.3125\n"
     ]
    }
   ],
   "source": [
    "# Longitudinal design\n",
    "\n",
    "long_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Longitudinal design'].iloc[i] == 'yes':\n",
    "        long_all += 1\n",
    "\n",
    "print('Longitudinal design: ', long_all, ' => ', long_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ed55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent on site (for data collection):  27  =>  0.84375\n"
     ]
    }
   ],
   "source": [
    "# Time spent on site (for data collection)\n",
    "\n",
    "time_spent_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Time spent on site (for data collection)'].iloc[i] != 'not specified':\n",
    "        time_spent_all += 1\n",
    "\n",
    "print('Time spent on site (for data collection): ', time_spent_all, ' => ', time_spent_all/purpose_len)\n",
    "\n",
    "time_spent_unique = df['Time spent on site (for data collection)'].unique()\n",
    "#time_spent_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ecca50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  3  =>  0.09375\n",
      "2:  7  =>  0.21875\n",
      "3:  14  =>  0.4375\n",
      "4:  6  =>  0.1875\n",
      "5:  1  =>  0.03125\n",
      "6:  1  =>  0.03125\n",
      "Team-based research:  29  =>  0.90625\n"
     ]
    }
   ],
   "source": [
    "# Number of authors  \n",
    "\n",
    "one_all = 0\n",
    "two_all = 0\n",
    "three_all = 0\n",
    "four_all = 0\n",
    "five_all = 0\n",
    "six_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of authors  '].iloc[i] == 1:\n",
    "        one_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 2:\n",
    "        two_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 3:\n",
    "        three_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 4:\n",
    "        four_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 5:\n",
    "        five_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 6:\n",
    "        six_all += 1\n",
    "\n",
    "print('1: ', one_all, ' => ', one_all/purpose_len)\n",
    "print('2: ', two_all, ' => ', two_all/purpose_len)\n",
    "print('3: ', three_all, ' => ', three_all/purpose_len)\n",
    "print('4: ', four_all, ' => ', four_all/purpose_len)\n",
    "print('5: ', five_all, ' => ', five_all/purpose_len)\n",
    "print('6: ', six_all, ' => ', six_all/purpose_len)\n",
    "print('Team-based research: ', purpose_len-one_all, ' => ', (purpose_len-one_all)/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f73fcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Involvement of the researcher:  6  =>  0.1875\n"
     ]
    }
   ],
   "source": [
    "# Involvement of the researcher\n",
    "\n",
    "involved_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Involvement of the researcher'].iloc[i] == 'involved':\n",
    "        involved_all += 1\n",
    "\n",
    "print('Involvement of the researcher: ', involved_all, ' => ', involved_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a723d1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different roles for multiple investigators:  6  =>  0.1875\n"
     ]
    }
   ],
   "source": [
    "# Different roles for multiple investigators\n",
    "\n",
    "diff_roles_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Different roles for multiple investigators'].iloc[i] == 'yes':\n",
    "        diff_roles_all += 1\n",
    "\n",
    "print('Different roles for multiple investigators: ', diff_roles_all, ' => ', diff_roles_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc134e3",
   "metadata": {},
   "source": [
    "_**Data Collection**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecc39cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  28  =>  0.875\n",
      "rough:  4  =>  0.125\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data collection process \n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Elucidation of the data collection process '].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data collection process '].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00317398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interviews :  29  =>  0.90625\n"
     ]
    }
   ],
   "source": [
    "# Interviews \n",
    "\n",
    "interviews_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Interviews '].iloc[i] == 'yes':\n",
    "        interviews_all += 1\n",
    "\n",
    "print('Interviews : ', interviews_all, ' => ', interviews_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a563dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi-structured:  18  =>  0.6206896551724138\n",
      "structured:  1  =>  0.034482758620689655\n"
     ]
    }
   ],
   "source": [
    "# Kind of interviews\n",
    "\n",
    "semi_all = 0\n",
    "struct_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Kind of interviews'].iloc[i] == 'semi-structured':\n",
    "        semi_all += 1\n",
    "    elif df_interv['Kind of interviews'].iloc[i] == 'structured':\n",
    "        struct_all += 1\n",
    "\n",
    "print('semi-structured: ', semi_all, ' => ', semi_all/interv_len)\n",
    "print('structured: ', struct_all, ' => ', struct_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "711ac7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:  2  =>  0.06896551724137931\n",
      "purposeful:  11  =>  0.3793103448275862\n",
      "snowball:  7  =>  0.2413793103448276\n",
      "maximum variation:  19  =>  0.6551724137931034\n"
     ]
    }
   ],
   "source": [
    "# Sampling strategy (interviews) (up to three)\n",
    "\n",
    "criterion_all = 0\n",
    "purposeful_all = 0\n",
    "snowball_all = 0\n",
    "variation_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if 'criterion' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        criterion_all += 1\n",
    "    if 'purposeful' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        purposeful_all += 1\n",
    "    if 'snowball' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        snowball_all += 1\n",
    "    if 'maximum variation' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        variation_all += 1\n",
    "\n",
    "print('criterion: ', criterion_all, ' => ', criterion_all/interv_len)\n",
    "print('purposeful: ', purposeful_all, ' => ', purposeful_all/interv_len)\n",
    "print('snowball: ', snowball_all, ' => ', snowball_all/interv_len)\n",
    "print('maximum variation: ', variation_all, ' => ', variation_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "914617f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviewees:  21  =>  0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "# Number of interviewees \n",
    "\n",
    "number_interviewees_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviewees '].iloc[i] != 'not specified':\n",
    "        number_interviewees_all += 1\n",
    "\n",
    "print('Number of interviewees: ', number_interviewees_all, ' => ', number_interviewees_all/interv_len)\n",
    "\n",
    "number_interviewees_unique = df_interv['Number of interviewees '].unique()\n",
    "#number_interviewees_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0abfd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviews:  23  =>  0.7931034482758621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified', 20, 18, 38, 158, 84, 17, 25, 50, 31, 83, 69, 46,\n",
       "       49, 29, 57, 33, 24, 23, 27], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of interviews\n",
    "\n",
    "number_interviews_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviews'].iloc[i] != 'not specified':\n",
    "        number_interviews_all += 1\n",
    "\n",
    "print('Number of interviews: ', number_interviews_all, ' => ', number_interviews_all/interv_len)\n",
    "\n",
    "number_interviews_unique = df_interv['Number of interviews'].unique()\n",
    "number_interviews_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c82fc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  8  =>  0.27586206896551724\n",
      "concrete examples:  8  =>  0.27586206896551724\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  3  =>  0.10344827586206896\n",
      "on request:  0  =>  0.0\n",
      "not specified:  10  =>  0.3448275862068966\n"
     ]
    }
   ],
   "source": [
    "# Use of an interview guide\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b23cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-test of interview guide:  1  =>  0.034482758620689655\n"
     ]
    }
   ],
   "source": [
    "# Pre-test of interview guide\n",
    "\n",
    "interv_guide_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Pre-test of interview guide'].iloc[i] == 'yes':\n",
    "        interv_guide_all += 1\n",
    "\n",
    "print('Pre-test of interview guide: ', interv_guide_all, ' => ', interv_guide_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca46a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview transcription:  25  =>  0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "# Interview transcription\n",
    "\n",
    "interv_transcr_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview transcription'].iloc[i] == 'yes':\n",
    "        interv_transcr_all += 1\n",
    "\n",
    "print('Interview transcription: ', interv_transcr_all, ' => ', interv_transcr_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b49ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview review:  6  =>  0.20689655172413793\n"
     ]
    }
   ],
   "source": [
    "# Interview review\n",
    "\n",
    "interv_review_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview review'].iloc[i] == 'yes':\n",
    "        interv_review_all += 1\n",
    "\n",
    "print('Interview review: ', interv_review_all, ' => ', interv_review_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cf7cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow up interviews:  6  =>  0.20689655172413793\n"
     ]
    }
   ],
   "source": [
    "# Follow up interviews\n",
    "\n",
    "interv_followup_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Follow up interviews'].iloc[i] == 'yes':\n",
    "        interv_followup_all += 1\n",
    "\n",
    "print('Follow up interviews: ', interv_followup_all, ' => ', interv_followup_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f57e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  19  =>  0.59375\n"
     ]
    }
   ],
   "source": [
    "# Observation \n",
    "\n",
    "obers_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Observation '].iloc[i] == 'yes':\n",
    "        obers_all += 1\n",
    "\n",
    "print('Observation: ', obers_all, ' => ', obers_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57d54da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentation:  26  =>  0.8125\n"
     ]
    }
   ],
   "source": [
    "# Documentation \n",
    "\n",
    "doc_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Documentation '].iloc[i] == 'yes':\n",
    "        doc_all += 1\n",
    "\n",
    "print('Documentation: ', doc_all, ' => ', doc_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "524c2285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionnaires:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires\n",
    "\n",
    "quest_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Questionnaires'].iloc[i] == 'yes':\n",
    "        quest_all += 1\n",
    "\n",
    "print('Questionnaires: ', quest_all, ' => ', quest_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "daa3d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  0  =>  0.0\n",
      "concrete examples:  0  =>  0.0\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  0  =>  0.0\n",
      "on request:  0  =>  0.0\n",
      "not specified:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires provided\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, quest_len):\n",
    "    if df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e28c6119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple data collection methods:  28  =>  0.875\n"
     ]
    }
   ],
   "source": [
    "# multiple data collection methods\n",
    "\n",
    "multiple_methods_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes'):\n",
    "        multiple_methods_all += 1\n",
    "\n",
    "print('multiple data collection methods: ', multiple_methods_all, ' => ', multiple_methods_all/purpose_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43bbcfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantitative:  0  =>  0.0\n",
      "qualitative:  30  =>  0.9375\n",
      "both:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Kind of data collected\n",
    "\n",
    "quantitative_all = 0\n",
    "qualitative_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Kind of data collected'].iloc[i] == 'quantitative':\n",
    "        quantitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'qualitative':\n",
    "        qualitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'both':\n",
    "        both_all += 1\n",
    "\n",
    "print('quantitative: ', quantitative_all, ' => ', quantitative_all/purpose_len)\n",
    "print('qualitative: ', qualitative_all, ' => ', qualitative_all/purpose_len)\n",
    "print('both: ', both_all, ' => ', both_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fbb295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data triangulation:  19  =>  0.59375\n"
     ]
    }
   ],
   "source": [
    "# Data triangulation \n",
    "\n",
    "data_tri_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data triangulation '].iloc[i] == 'yes':\n",
    "        data_tri_all += 1\n",
    "\n",
    "print('Data triangulation: ', data_tri_all, ' => ', data_tri_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03439d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data collection:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data collection\n",
    "\n",
    "researcher_tri_data_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Researcher triangulation during data collection'].iloc[i] == 'yes':\n",
    "        researcher_tri_data_all += 1\n",
    "\n",
    "print('Researcher triangulation during data collection: ', researcher_tri_data_all, ' => ', researcher_tri_data_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "306c4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data collection:  13  =>  0.40625\n"
     ]
    }
   ],
   "source": [
    "# Number of researchers conducting data collection\n",
    "\n",
    "researchers_data_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of researchers conducting data collection'].iloc[i] != 'not specified':\n",
    "        researchers_data_all += 1\n",
    "\n",
    "print('Number of researchers conducting data collection: ', researchers_data_all, ' => ', researchers_data_all/purpose_len)\n",
    "\n",
    "researchers_data_unique = df['Number of researchers conducting data collection'].unique()\n",
    "#researchers_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4859d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study protocol:  3  =>  0.09375\n"
     ]
    }
   ],
   "source": [
    "# Case study protocol\n",
    "\n",
    "protocol_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case study protocol'].iloc[i] == 'yes':\n",
    "        protocol_all += 1\n",
    "\n",
    "print('Case study protocol: ', protocol_all, ' => ', protocol_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6baa78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study database:  4  =>  0.125\n"
     ]
    }
   ],
   "source": [
    "# Case study database \n",
    "\n",
    "database_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case study database '].iloc[i] == 'yes':\n",
    "        database_all += 1\n",
    "\n",
    "print('Case study database: ', database_all, ' => ', database_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a387e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap of data collection and analysis:  11  =>  0.34375\n"
     ]
    }
   ],
   "source": [
    "# Overlap of data collection and analysis\n",
    "\n",
    "overlap_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Overlap of data collection and analysis'].iloc[i] == 'yes':\n",
    "        overlap_all += 1\n",
    "\n",
    "print('Overlap of data collection and analysis: ', overlap_all, ' => ', overlap_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942570b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a093f90",
   "metadata": {},
   "source": [
    "_**Analysis**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f50a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  26  =>  0.8125\n",
      "rough:  5  =>  0.15625\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data analysis process\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Elucidation of the data analysis process'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data analysis process'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3dd4f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field notes:  13  =>  0.40625\n"
     ]
    }
   ],
   "source": [
    "# Field notes\n",
    "\n",
    "notes_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Field notes'].iloc[i] == 'yes':\n",
    "        notes_all += 1\n",
    "\n",
    "print('Field notes: ', notes_all, ' => ', notes_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af627c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coding of raw data:  28  =>  0.875\n"
     ]
    }
   ],
   "source": [
    "# Coding of raw data\n",
    "\n",
    "code_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Coding of raw data'].iloc[i] == 'yes':\n",
    "        code_all += 1\n",
    "\n",
    "print('Coding of raw data: ', code_all, ' => ', code_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5479f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  4  =>  0.14285714285714285\n",
      "complete in appendix:  6  =>  0.21428571428571427\n",
      "partially:  9  =>  0.32142857142857145\n",
      "on request:  0  =>  0.0\n",
      "no:  9  =>  0.32142857142857145\n"
     ]
    }
   ],
   "source": [
    "# Coding scheme available\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "partially_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding scheme available'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, partially':\n",
    "        partially_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'no':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/code_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/code_len)\n",
    "print('partially: ', partially_all, ' => ', partially_all/code_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/code_len)\n",
    "print('no: ', not_spec_all, ' => ', not_spec_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "943995ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of coding scheme:  3  =>  0.10714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Validation of coding scheme\n",
    "\n",
    "validation_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Validation of coding scheme'].iloc[i] == 'yes':\n",
    "        validation_all += 1\n",
    "\n",
    "print('Validation of coding scheme: ', validation_all, ' => ', validation_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e1dcbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example codes available:  11  =>  0.39285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Example codes available\n",
    "\n",
    "example_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Example codes available'].iloc[i] == 'yes':\n",
    "        example_all += 1\n",
    "\n",
    "print('Example codes available: ', example_all, ' => ', example_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6b98d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data analysis:  12  =>  0.375\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data analysis\n",
    "\n",
    "researcher_tri_analysis_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Researcher triangulation during data analysis'].iloc[i] == 'yes':\n",
    "        researcher_tri_analysis_all += 1\n",
    "\n",
    "print('Researcher triangulation during data analysis: ', researcher_tri_analysis_all, ' => ', researcher_tri_analysis_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52a38837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data analysis:  16  =>  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified', 'min. 2', 2, 1, 4, '2 to 3', 3], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of researchers conducting data analysis\n",
    "\n",
    "researchers_analysis_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of researchers conducting data analysis'].iloc[i] != 'not specified':\n",
    "        researchers_analysis_all += 1\n",
    "\n",
    "print('Number of researchers conducting data analysis: ', researchers_analysis_all, ' => ', researchers_analysis_all/purpose_len)\n",
    "\n",
    "researchers_analysis_unique = df['Number of researchers conducting data analysis'].unique()\n",
    "researchers_analysis_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6a69c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-rater reliability test :  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Inter-rater reliability test \n",
    "\n",
    "inter_rater_all = 0\n",
    "\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Inter-rater reliability test '].iloc[i] == 'yes':\n",
    "        inter_rater_all += 1\n",
    "\n",
    "print('Inter-rater reliability test : ', inter_rater_all, ' => ', inter_rater_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6111b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-rater agreement ratio\n",
    "\n",
    "inter_ratio_unique = df['Inter-rater agreement ratio'].unique()\n",
    "#inter_ratio_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1b5c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLAS-ti:  3  =>  0.10714285714285714\n",
      "Nvivo:  5  =>  0.17857142857142858\n",
      "both:  20  =>  0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Coding software\n",
    "\n",
    "atlas_all = 0\n",
    "nvivo_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding software'].iloc[i] == 'ATLAS-ti':\n",
    "        atlas_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'Nvivo':\n",
    "        nvivo_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('ATLAS-ti: ', atlas_all, ' => ', atlas_all/code_len)\n",
    "print('Nvivo: ', nvivo_all, ' => ', nvivo_all/code_len)\n",
    "print('both: ', no_all, ' => ', no_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "34c8bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicitly:  2  =>  0.0625\n",
      "implicitly:  10  =>  0.3125\n",
      "no:  20  =>  0.625\n"
     ]
    }
   ],
   "source": [
    "# Data displays (technique)\n",
    "\n",
    "expl_all = 0\n",
    "impl_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data displays (technique)'].iloc[i] == 'yes, explicitly':\n",
    "        expl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'yes, implicitly':\n",
    "        impl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('explicitly: ', expl_all, ' => ', expl_all/purpose_len)\n",
    "print('implicitly: ', impl_all, ' => ', impl_all/purpose_len)\n",
    "print('no: ', no_all, ' => ', no_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bd54b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data displays:  32  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Data displays\n",
    "\n",
    "displays_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data displays'].iloc[i] == 'yes':\n",
    "        displays_all += 1\n",
    "\n",
    "print('Data displays: ', displays_all, ' => ', displays_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9eb2abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexible and opportunistic process:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Flexible and opportunistic process\n",
    "\n",
    "flexible_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Flexible and opportunistic process'].iloc[i] == 'yes':\n",
    "        flexible_all += 1\n",
    "\n",
    "print('Flexible and opportunistic process: ', flexible_all, ' => ', flexible_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eef63c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical chain of evidence:  31  =>  0.96875\n"
     ]
    }
   ],
   "source": [
    "# Logical chain of evidence\n",
    "\n",
    "evidence_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Logical chain of evidence'].iloc[i] == 'yes':\n",
    "        evidence_all += 1\n",
    "\n",
    "print('Logical chain of evidence: ', evidence_all, ' => ', evidence_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af4721f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation building (only exploratory):  31  =>  0.96875\n"
     ]
    }
   ],
   "source": [
    "# Explanation building (only exploratory)\n",
    "\n",
    "explan_build_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['Explanation building (only exploratory)'].iloc[i] == 'yes':\n",
    "            explan_build_all += 1\n",
    "\n",
    "    print('Explanation building (only exploratory): ', explan_build_all, ' => ', explan_build_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d5518e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for cross-case patterns (only multiple CS):  9  =>  0.9\n"
     ]
    }
   ],
   "source": [
    "# Search for cross-case patterns (only multiple CS)\n",
    "\n",
    "cross_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Search for cross-case patterns (only multiple CS)'].iloc[i] == 'yes':\n",
    "        cross_all += 1\n",
    "\n",
    "print('Search for cross-case patterns (only multiple CS): ', cross_all, ' => ', cross_all/multiple_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "491822ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  31  =>  0.96875\n",
      "rough:  1  =>  0.03125\n"
     ]
    }
   ],
   "source": [
    "# Description of the observed world\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Description of the observed world'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Description of the observed world'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aeb80787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excerpts used:  30  =>  0.9375\n",
      "quotes:  30  =>  0.9375\n",
      "figures:  1  =>  0.03125\n",
      "screenshots:  1  =>  0.03125\n",
      "blog:  1  =>  0.03125\n"
     ]
    }
   ],
   "source": [
    "# Excerpts of raw data in case report\n",
    "\n",
    "quotes_all = 0\n",
    "figures_all = 0\n",
    "screenshots_all = 0\n",
    "blog_all = 0\n",
    "excerpts_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Excerpts of raw data in case report'].iloc[i] != 'no':\n",
    "        excerpts_all += 1\n",
    "\n",
    "print('excerpts used: ', excerpts_all, ' => ', excerpts_all/purpose_len)\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if 'quotes' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        quotes_all += 1\n",
    "    if 'figures' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        figures_all += 1\n",
    "    if 'screenshots' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        screenshots_all += 1\n",
    "    if 'blog' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        blog_all += 1\n",
    "\n",
    "print('quotes: ', quotes_all, ' => ', quotes_all/purpose_len)\n",
    "print('figures: ', figures_all, ' => ', figures_all/purpose_len)\n",
    "print('screenshots: ', screenshots_all, ' => ', screenshots_all/purpose_len)\n",
    "print('blog: ', blog_all, ' => ', blog_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5418ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project reviews:  14  =>  0.4375\n"
     ]
    }
   ],
   "source": [
    "# Project reviews\n",
    "\n",
    "project_review_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Project reviews'].iloc[i] == 'yes':\n",
    "        project_review_all += 1\n",
    "\n",
    "print('Project reviews: ', project_review_all, ' => ', project_review_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8dfaad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with conflicting literature (only exploratory):  17  =>  0.53125\n"
     ]
    }
   ],
   "source": [
    "# Comparison with conflicting literature (only exploratory)\n",
    "\n",
    "confl_lit_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['Comparison with conflicting literature (only exploratory)'].iloc[i] == 'yes':\n",
    "            confl_lit_all += 1\n",
    "\n",
    "    print('Comparison with conflicting literature (only exploratory): ', confl_lit_all, ' => ', confl_lit_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1d2e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with similar literature (only exploratory):  30  =>  0.9375\n"
     ]
    }
   ],
   "source": [
    "# Comparison with similar literature (only exploratory)\n",
    "\n",
    "sim_lit_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['Comparison with similar literature (only exploratory)'].iloc[i] == 'yes':\n",
    "            sim_lit_all += 1\n",
    "\n",
    "    print('Comparison with similar literature (only exploratory): ', sim_lit_all, ' => ', sim_lit_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29894814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1107cb0",
   "metadata": {},
   "source": [
    "_**Miscellaneous**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "395b86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key case study characteristics summarized :  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Key case study characteristics summarized \n",
    "\n",
    "cs_charact_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Key case study characteristics summarized '].iloc[i] == 'yes':\n",
    "        cs_charact_all += 1\n",
    "\n",
    "print('Key case study characteristics summarized : ', cs_charact_all, ' => ', cs_charact_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e90752cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methodological literature cited:  32  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Methodological literature cited\n",
    "\n",
    "methodol_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Methodological literature cited'].iloc[i] == 'yes':\n",
    "        methodol_all += 1\n",
    "\n",
    "print('Methodological literature cited: ', methodol_all, ' => ', methodol_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d30b48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other case studies cited:  20  =>  0.625\n"
     ]
    }
   ],
   "source": [
    "#Other case studies cited\n",
    "\n",
    "other_cs_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Other case studies cited'].iloc[i] == 'yes':\n",
    "        other_cs_all += 1\n",
    "\n",
    "print('Other case studies cited: ', other_cs_all, ' => ', other_cs_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e81544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online-Appendix:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "#Online-Appendix\n",
    "\n",
    "online_appendix_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Online-Appendix'].iloc[i] == 'yes':\n",
    "        online_appendix_all += 1\n",
    "\n",
    "print('Online-Appendix: ', online_appendix_all, ' => ', online_appendix_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7149084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
