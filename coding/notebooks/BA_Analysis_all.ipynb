{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fffbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8833f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Excel file with data\n",
    "xlx = '../data/Coding_JSIS_MISQ_V5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f859123d",
   "metadata": {},
   "source": [
    "# All journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11ad71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data amount:  35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Autor/en</th>\n",
       "      <th>Use of CSR stated</th>\n",
       "      <th>Use of CSR stated DETAIL</th>\n",
       "      <th>CSR used in keywords</th>\n",
       "      <th>CSR used in keywords DETAIL</th>\n",
       "      <th>...</th>\n",
       "      <th>Comparison with similar literature (only exploratory) DETAIL</th>\n",
       "      <th>Key case study characteristics summarized</th>\n",
       "      <th>Key case study characteristics summarized  DETAIL</th>\n",
       "      <th>Methodological literature cited</th>\n",
       "      <th>Methodological literature cited DETAIL</th>\n",
       "      <th>Other case studies cited</th>\n",
       "      <th>Other case studies cited DETAIL</th>\n",
       "      <th>Online-Appendix</th>\n",
       "      <th>Online-Appendix DETAIL</th>\n",
       "      <th>Classification in terms of methodological rigor (descending: ++, +, o, -)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>A strategic activity model of Enterprise Syste...</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Jenny Leonard, Helen Higson</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.1. Case study design + A case study approach...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>This contributes to understanding some aspects...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yin, R., 2003. Case Study Research: Design and...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>Forced coopetition in IT multi-sourcing</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Martin Wiener, Carol Saunders</td>\n",
       "      <td>yes</td>\n",
       "      <td>To develop a deeper understanding of this mode...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>Turning to the critical factors that enabled G...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yin, R., 1994. Case Study Research: Design and...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Journal                                              Titel  Jahr  Volume  \\\n",
       "0    JSIS  A strategic activity model of Enterprise Syste...  2014      23   \n",
       "1    JSIS            Forced coopetition in IT multi-sourcing  2014      23   \n",
       "\n",
       "   Issue                       Autor/en Use of CSR stated  \\\n",
       "0      1    Jenny Leonard, Helen Higson               yes   \n",
       "1      3  Martin Wiener, Carol Saunders               yes   \n",
       "\n",
       "                            Use of CSR stated DETAIL CSR used in keywords  \\\n",
       "0  3.1. Case study design + A case study approach...                   no   \n",
       "1  To develop a deeper understanding of this mode...                   no   \n",
       "\n",
       "  CSR used in keywords DETAIL  ...  \\\n",
       "0                           -  ...   \n",
       "1                           -  ...   \n",
       "\n",
       "  Comparison with similar literature (only exploratory) DETAIL  \\\n",
       "0  This contributes to understanding some aspects...             \n",
       "1  Turning to the critical factors that enabled G...             \n",
       "\n",
       "  Key case study characteristics summarized   \\\n",
       "0                                         no   \n",
       "1                                         no   \n",
       "\n",
       "  Key case study characteristics summarized  DETAIL  \\\n",
       "0                                                 -   \n",
       "1                                                 -   \n",
       "\n",
       "  Methodological literature cited  \\\n",
       "0                             yes   \n",
       "1                             yes   \n",
       "\n",
       "              Methodological literature cited DETAIL Other case studies cited  \\\n",
       "0  Yin, R., 2003. Case Study Research: Design and...                       no   \n",
       "1  Yin, R., 1994. Case Study Research: Design and...                       no   \n",
       "\n",
       "  Other case studies cited DETAIL Online-Appendix Online-Appendix DETAIL  \\\n",
       "0                               -              no                      -   \n",
       "1                               -              no                      -   \n",
       "\n",
       "  Classification in terms of methodological rigor (descending: ++, +, o, -)  \n",
       "0                                                  -                         \n",
       "1                                                  +                         \n",
       "\n",
       "[2 rows x 187 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform Excel file to dataframe\n",
    "\n",
    "df = pd.read_excel(xlx, header=0)\n",
    "all_len = len(df)\n",
    "\n",
    "print('Data amount: ', all_len)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc66fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptive purpose:  2  =>  0.05714285714285714\n",
      "explanatory purpose:  1  =>  0.02857142857142857\n",
      "exploratory purpose:  32  =>  0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# dataframes for research purposes\n",
    "\n",
    "# 1. descriptive\n",
    "df_descr = df.loc[df['Research purpose'] == 'descriptive']\n",
    "descr_len = len(df_descr)\n",
    "print('descriptive purpose: ', descr_len, ' => ', descr_len/all_len)\n",
    "#df_descr.head(2)\n",
    "\n",
    "# 2. explanatory\n",
    "df_explan = df.loc[df['Research purpose'] == 'explanatory']\n",
    "explan_len = len(df_explan)\n",
    "print('explanatory purpose: ', explan_len, ' => ', explan_len/all_len)\n",
    "#df_explan.head(2)\n",
    "\n",
    "# 3. exploratory\n",
    "df_explor = df.loc[df['Research purpose'] == 'exploratory']\n",
    "explor_len = len(df_explor)\n",
    "print('exploratory purpose: ', explor_len, ' => ', explor_len/all_len)\n",
    "#df_explor.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2019b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number single cases:  23  =>  0.6571428571428571\n",
      "Number multiple cases:  12  =>  0.34285714285714286\n"
     ]
    }
   ],
   "source": [
    "# dataframes for single and multiple CS\n",
    "\n",
    "# 1. single CS\n",
    "df_single = df.loc[df['Number of cases'] == 1]\n",
    "single_len = len(df_single)\n",
    "print('Number single cases: ', single_len, ' => ', single_len/all_len)\n",
    "#df_single.head()\n",
    "\n",
    "#2. multiple CS\n",
    "df_multiple = df.loc[df['Number of cases'] > 1]\n",
    "multiple_len = len(df_multiple)\n",
    "print('Number multiple cases: ', multiple_len, ' => ', multiple_len/all_len)\n",
    "#df_multiple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9e4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number interview cases:  32\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including interviews\n",
    "\n",
    "df_interv = df.loc[df['Interviews '] == 'yes']\n",
    "interv_len = len(df_interv)\n",
    "print('Number interview cases: ', interv_len)\n",
    "#df_interv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333fe09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Questionnaires cases:  0\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including questionnaires\n",
    "\n",
    "df_quest = df.loc[df['Questionnaires'] == 'yes']\n",
    "quest_len = len(df_quest)\n",
    "print('Number Questionnaires cases: ', quest_len)\n",
    "#df_quest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a288587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number coding cases:  31\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including coding\n",
    "\n",
    "df_code = df.loc[df['Coding of raw data'] == 'yes']\n",
    "code_len = len(df_code)\n",
    "print('Number coding cases: ', code_len)\n",
    "#df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc743d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c426ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of CSR stated:  33  =>  0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Use of CSR stated\n",
    "\n",
    "csr_stated_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Use of CSR stated'].iloc[i] == 'yes':\n",
    "        csr_stated_all += 1\n",
    "\n",
    "print('Use of CSR stated: ', csr_stated_all, ' => ', csr_stated_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882def82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR used in keywords:  9  =>  0.2571428571428571\n"
     ]
    }
   ],
   "source": [
    "# CSR used in keywords\n",
    "\n",
    "keywords_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['CSR used in keywords'].iloc[i] == 'yes':\n",
    "        keywords_all += 1\n",
    "\n",
    "print('CSR used in keywords: ', keywords_all, ' => ', keywords_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f27e5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Case studies” stated instead of “multiple case study”:  6  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# “Case studies” stated instead of “multiple case study”\n",
    "\n",
    "mCS_stated_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['“Case studies” stated instead of “multiple case study”'].iloc[i] == 'yes':\n",
    "        mCS_stated_all += 1\n",
    "\n",
    "print('“Case studies” stated instead of “multiple case study”: ', mCS_stated_all, ' => ', mCS_stated_all/multiple_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8022d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f11af1",
   "metadata": {},
   "source": [
    "_**Research Design**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3fc318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive all:  2  =>  0.05714285714285714\n",
      "Explanatory all:  1  =>  0.02857142857142857\n",
      "Exploratory all:  32  =>  0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# research purpose\n",
    "\n",
    "descr_all = 0\n",
    "explan_all = 0\n",
    "explor_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Research purpose'].iloc[i] == 'descriptive':\n",
    "        descr_all += 1\n",
    "    elif df['Research purpose'].iloc[i] == 'explanatory':\n",
    "        explan_all += 1\n",
    "    elif df['Research purpose'].iloc[i] == 'exploratory':\n",
    "        explor_all += 1\n",
    "\n",
    "print('Descriptive all: ', descr_all, ' => ', descr_all/all_len)\n",
    "print('Explanatory all: ', explan_all, ' => ', explan_all/all_len)\n",
    "print('Exploratory all: ', explor_all, ' => ', explor_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b63df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting CSR:  26  =>  0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting CSR\n",
    "\n",
    "rationale_csr_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Rationale for conducting CSR'].iloc[i] == 'yes':\n",
    "        rationale_csr_all += 1\n",
    "\n",
    "print('Rationale for conducting CSR: ', rationale_csr_all, ' => ', rationale_csr_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a42a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research question all:  26  =>  0.7428571428571429\n",
      "goal with interrogative all:  5  =>  0.14285714285714285\n",
      "goal without interrogative all:  4  =>  0.11428571428571428\n",
      "\n",
      "Research question or goal with interrogative all:  31  =>  0.8857142857142857\n",
      "\n",
      "stat/chi2 is 24.16706037824469\n",
      "p value is 8.833019633003729e-07\n",
      "dof is 1\n",
      "expected is [[89.82110092 93.17889908]\n",
      " [17.17889908 17.82110092]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Clear research questions \n",
    "\n",
    "question_all = 0\n",
    "w_interr_all = 0\n",
    "wo_interr_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Clear research questions '].iloc[i] == 'yes':\n",
    "        question_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal with interrogative':\n",
    "        w_interr_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal without interrogative':\n",
    "        wo_interr_all += 1\n",
    "\n",
    "print('Research question all: ', question_all, ' => ', question_all/all_len)\n",
    "print('goal with interrogative all: ', w_interr_all, ' => ', w_interr_all/all_len)\n",
    "print('goal without interrogative all: ', wo_interr_all, ' => ', wo_interr_all/all_len)\n",
    "print('')\n",
    "print('Research question or goal with interrogative all: ', question_all+w_interr_all, ' => ',  (question_all+w_interr_all)/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [76, 107]\n",
    "\n",
    "# my result\n",
    "my = [question_all+w_interr_all, all_len-(question_all+w_interr_all)]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c1c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQ types:  ['how, how' '-' 'how' 'what, how' 'how, why' 'how, what'\n",
      " 'what, to what, what' 'how, to what' 'what' 'does, how']\n",
      "Number research questions or goal with interrogative:  31\n",
      "how absolute:  33\n",
      "why absolute:  3\n",
      "to what absolute:  2\n",
      "what absolute:  7\n",
      "does absolute:  1\n"
     ]
    }
   ],
   "source": [
    "# Types of research questions \n",
    "\n",
    "types_rq_un = df['Types of research questions '].unique()\n",
    "print('RQ types: ', types_rq_un)\n",
    "\n",
    "amount_rq = 0\n",
    "for i in range(0, all_len):\n",
    "    if df['Types of research questions '].iloc[i] != '-':\n",
    "        amount_rq += 1\n",
    "\n",
    "print('Number research questions or goal with interrogative: ', amount_rq)\n",
    "\n",
    "\n",
    "# possible combination of types of research question\n",
    "\n",
    "how = 0\n",
    "why = 0\n",
    "to_what = 0\n",
    "what = 0\n",
    "does = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Types of research questions '].iloc[i] == 'how, how':\n",
    "        how += 2\n",
    "    elif df['Types of research questions '].iloc[i] == 'how':\n",
    "        how += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'what, how':\n",
    "        how += 1\n",
    "        what += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'how, why':\n",
    "        how += 1\n",
    "        why += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'how, what':\n",
    "        how += 1\n",
    "        what += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'what, to what, what':\n",
    "        what += 2\n",
    "        to_what += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'how, to what':\n",
    "        how += 1\n",
    "        to_what += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'what':\n",
    "        what += 1\n",
    "    elif df['Types of research questions '].iloc[i] == 'does, how':\n",
    "        does += 1\n",
    "        how += 1\n",
    "\n",
    "print('how absolute: ', how)\n",
    "print('why absolute: ', why)\n",
    "print('to what absolute: ', to_what)\n",
    "print('what absolute: ', what)\n",
    "print('does absolute: ', does)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527a4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priori specification of constructs (only exploratory):  28  =>  0.875\n",
      "\n",
      "stat/chi2 is 0.6943152695105822\n",
      "p value is 0.4047004645083745\n",
      "dof is 1\n",
      "expected is [[43.95348837 10.04651163]\n",
      " [26.04651163  5.95348837]]\n",
      "Independent (H0 holds true)\n"
     ]
    }
   ],
   "source": [
    "# A priori specification of constructs (only exploratory)\n",
    "\n",
    "a_priori_all = 0\n",
    "\n",
    "for i in range(0, explor_all):\n",
    "    if df_explor['A priori specification of constructs (only exploratory)'].iloc[i] == 'yes':\n",
    "        a_priori_all += 1\n",
    "\n",
    "print('A priori specification of constructs (only exploratory): ', a_priori_all, ' => ', a_priori_all/explor_all)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [42, 12]\n",
    "\n",
    "# my result\n",
    "my = [a_priori_all, explor_all-a_priori_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cec10476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean theoretical slate (only exploratory):  15  =>  0.46875\n",
      "\n",
      "stat/chi2 is 9.623319470600546\n",
      "p value is 0.0019212216743659648\n",
      "dof is 1\n",
      "expected is [[37.04651163 16.95348837]\n",
      " [21.95348837 10.04651163]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Clean theoretical slate (only exploratory)\n",
    "\n",
    "cl_theor_all = 0\n",
    "\n",
    "for i in range(0, explor_all):\n",
    "    if df_explor['Clean theoretical slate (only exploratory)'].iloc[i] == 'yes':\n",
    "        cl_theor_all += 1\n",
    "\n",
    "print('Clean theoretical slate (only exploratory): ', cl_theor_all, ' => ', cl_theor_all/explor_all)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [44, 10]\n",
    "\n",
    "# my result\n",
    "my = [cl_theor_all, explor_all-cl_theor_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d77d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory of interest stated (only explanatory):  1  =>  1.0\n",
      "\n",
      "fisher is (nan, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Theory of interest stated (only explanatory)\n",
    "\n",
    "theory_int_all = 0\n",
    "\n",
    "for i in range(0, explan_all):\n",
    "    if df_explan['Theory of interest stated (only explanatory)'].iloc[i] == 'yes':\n",
    "        theory_int_all += 1\n",
    "\n",
    "print('Theory of interest stated (only explanatory): ', theory_int_all, ' => ', theory_int_all/explan_all)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [17, 0]\n",
    "\n",
    "# my result\n",
    "my = [theory_int_all, explan_all-theory_int_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c496019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from theory stated  (only explanatory):  1  =>  1.0\n",
      "\n",
      "fisher is (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Predictions from theory stated  (only explanatory)\n",
    "\n",
    "predict_all = 0\n",
    "\n",
    "for i in range(0, explan_all):\n",
    "    if df_explan['Predictions from theory stated  (only explanatory)'].iloc[i] == 'yes':\n",
    "        predict_all += 1\n",
    "\n",
    "print('Predictions from theory stated  (only explanatory): ', predict_all, ' => ', predict_all/explan_all)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [16, 1]\n",
    "\n",
    "# my result\n",
    "my = [predict_all, explan_all-predict_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7c9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of rival theories (only explanatory):  0  =>  0.0\n",
      "\n",
      "fisher is (inf, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Use of rival theories (only explanatory)\n",
    "\n",
    "rival_all = 0\n",
    "\n",
    "for i in range(0, explan_all):\n",
    "    if df_explan['Use of rival theories (only explanatory)'].iloc[i] == 'yes':\n",
    "        rival_all += 1\n",
    "\n",
    "print('Use of rival theories (only explanatory): ', rival_all, ' => ', rival_all/explan_all)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [5, 12]\n",
    "\n",
    "# my result\n",
    "my = [rival_all, explan_all-rival_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55e8de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case acquisition strategy:  4  =>  0.11428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Case acquisition strategy\n",
    "\n",
    "acquisition_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case acquisition strategy'].iloc[i] == 'yes':\n",
    "        acquisition_all += 1\n",
    "\n",
    "print('Case acquisition strategy: ', acquisition_all, ' => ', acquisition_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "082a3b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases unique:  [ 2  1 22  5 20  3  4]\n",
      "multiple cases mean:  5.75\n",
      "multiple cases median:  2.5\n",
      "2 absolute:  6\n",
      "3 absolute:  2\n",
      "4 absolute:  1\n",
      "5 absolute:  1\n",
      "20 absolute:  1\n",
      "22 absolute:  2\n",
      "\n",
      "stat/chi2 is 0.24353124953582483\n",
      "p value is 0.6216672131128154\n",
      "dof is 1\n",
      "expected is [[ 72.19266055 110.80733945]\n",
      " [ 13.80733945  21.19266055]]\n",
      "Independent (H0 holds true)\n"
     ]
    }
   ],
   "source": [
    "# Number of cases\n",
    "\n",
    "number_cases = df['Number of cases'].unique()\n",
    "print('Number of cases unique: ', number_cases)\n",
    "\n",
    "mean = df_multiple['Number of cases'].mean()\n",
    "print('multiple cases mean: ', mean)\n",
    "\n",
    "median = df_multiple['Number of cases'].median()\n",
    "print('multiple cases median: ', median)\n",
    "\n",
    "\n",
    "# number cases sum\n",
    "two = 0\n",
    "three = 0\n",
    "four = 0\n",
    "five = 0\n",
    "twenty = 0\n",
    "twentytwo = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Number of cases'].iloc[i] == 2:\n",
    "        two += 1\n",
    "    elif df_multiple['Number of cases'].iloc[i] == 3:\n",
    "        three += 1\n",
    "    elif df_multiple['Number of cases'].iloc[i] == 4:\n",
    "        four += 1\n",
    "    elif df_multiple['Number of cases'].iloc[i] == 5:\n",
    "        five += 1\n",
    "    elif df_multiple['Number of cases'].iloc[i] == 20:\n",
    "        twenty += 1\n",
    "    elif df_multiple['Number of cases'].iloc[i] == 22:\n",
    "        twentytwo += 2\n",
    "\n",
    "print('2 absolute: ', two)\n",
    "print('3 absolute: ', three)\n",
    "print('4 absolute: ', four)\n",
    "print('5 absolute: ', five)\n",
    "print('20 absolute: ', twenty)\n",
    "print('22 absolute: ', twentytwo)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [74, 109]\n",
    "\n",
    "# my result\n",
    "my = [multiple_len, all_len-multiple_len]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0930a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting a single/multiple case study:  21  =>  0.6\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting a single/multiple case study\n",
    "\n",
    "rationale_single_multiple_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Rationale for conducting a single/multiple case study'].iloc[i] == 'yes':\n",
    "        rationale_single_multiple_all += 1\n",
    "\n",
    "print('Rationale for conducting a single/multiple case study: ', rationale_single_multiple_all, ' => ', rationale_single_multiple_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed72db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For unknown reasons the case \"criterion, convenience\" is not recognized by the program. Therefore adding the values by hand.\n",
      "\n",
      "convenience:  1  =>  0.043478260869565216\n",
      "criterion:  1  =>  0.043478260869565216\n",
      "critical:  0  =>  0.0\n",
      "extreme and unique:  6  =>  0.2608695652173913\n",
      "intensity:  1  =>  0.043478260869565216\n",
      "revelatory:  5  =>  0.21739130434782608\n",
      "theoretical:  1  =>  0.043478260869565216\n",
      "typical:  0  =>  0.0\n",
      "nature single described:  13  =>  0.5652173913043478\n",
      "nature single not specified:  10  =>  0.4347826086956522\n"
     ]
    }
   ],
   "source": [
    "# Nature of single-case design\n",
    "\n",
    "convenience_all = 0\n",
    "criterion_all = 0\n",
    "critical_all = 0\n",
    "extreme_all = 0\n",
    "intensity_all = 0\n",
    "revelatory_all = 0\n",
    "theoretical_all = 0\n",
    "typical_all = 0\n",
    "unique_all = 0\n",
    "\n",
    "for i in range(0, single_len):\n",
    "    if df_single['Nature of single-case design'].iloc[i] == 'criterion, convenience':\n",
    "        criterion_all += 1\n",
    "        convenience_all += 1\n",
    "    if df_single['Nature of single-case design'].iloc[i] == 'critical':\n",
    "        critical_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'extreme':\n",
    "        extreme_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'intensity':\n",
    "        intensity_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'revelatory':\n",
    "        revelatory_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'theoretical':\n",
    "        theoretical_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'typical':\n",
    "        typical_all += 1\n",
    "    elif df_single['Nature of single-case design'].iloc[i] == 'unique':\n",
    "        unique_all += 1    \n",
    "\n",
    "nature_sum = criterion_all + extreme_all + intensity_all + revelatory_all + theoretical_all + typical_all + unique_all\n",
    "        \n",
    "print('For unknown reasons the case \"criterion, convenience\" is not recognized by the program. Therefore adding the values by hand.')\n",
    "criterion_all += 1\n",
    "convenience_all += 1\n",
    "\n",
    "print('')\n",
    "print('convenience: ', convenience_all, ' => ', convenience_all/single_len)\n",
    "print('criterion: ', criterion_all, ' => ', criterion_all/single_len)\n",
    "print('critical: ', critical_all, ' => ', critical_all/single_len)\n",
    "print('extreme and unique: ', extreme_all+unique_all, ' => ', (extreme_all+unique_all)/single_len)\n",
    "print('intensity: ', intensity_all, ' => ', intensity_all/single_len)\n",
    "print('revelatory: ', revelatory_all, ' => ', revelatory_all/single_len)\n",
    "print('theoretical: ', theoretical_all, ' => ', theoretical_all/single_len)\n",
    "print('typical: ', typical_all, ' => ', typical_all/single_len)\n",
    "#print('unique: ', unique_all, ' => ', unique_all/single_len)\n",
    "print('nature single described: ', nature_sum, ' => ', nature_sum/single_len)\n",
    "print('nature single not specified: ', single_len-nature_sum, ' => ', 1-(nature_sum/single_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5343de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literal:  5  =>  0.4166666666666667\n",
      "theoretical:  4  =>  0.3333333333333333\n",
      "replic. logic described:  9  =>  0.75\n",
      "replic. logic not specified:  3  =>  0.25\n"
     ]
    }
   ],
   "source": [
    "# Replication logic in multiple-case design\n",
    "\n",
    "literal_all = 0\n",
    "theoretical_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Replication logic in multiple-case design'].iloc[i] == 'literal':\n",
    "        literal_all += 1\n",
    "    elif df_multiple['Replication logic in multiple-case design'].iloc[i] == 'theoretical':\n",
    "        theoretical_all += 1\n",
    "\n",
    "print('literal: ', literal_all, ' => ', literal_all/multiple_len)\n",
    "print('theoretical: ', theoretical_all, ' => ', theoretical_all/multiple_len)\n",
    "print('replic. logic described: ', literal_all+theoretical_all, ' => ', (literal_all+theoretical_all)/multiple_len)\n",
    "print('replic. logic not specified: ', multiple_len-(literal_all+theoretical_all), ' => ', 1-((literal_all+theoretical_all)/multiple_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "922a9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s reasonably chosen:  29  =>  0.8285714285714286\n",
      "\n",
      "single Case reasonably chosen:  20  =>  0.8695652173913043\n",
      "\n",
      "single stat/chi2 is 50.26891633078924\n",
      "single p value is 1.3405622266927397e-12\n",
      "single dof is 1\n",
      "single expected is [[30.08571429 86.91428571]\n",
      " [ 5.91428571 17.08571429]]\n",
      "Dependent (reject H0)\n",
      "\n",
      "multiple Cases reasonably chosen:  9  =>  0.75\n",
      "\n",
      "multiple stat/chi2 is 6.400627104377104\n",
      "multiple p value is 0.011408006072346584\n",
      "multiple dof is 1\n",
      "multiple expected is [[28.44827586 46.55172414]\n",
      " [ 4.55172414  7.44827586]]\n",
      "Dependent (reject H0)\n",
      "\n",
      "fisher is (0.1568627450980392, 0.00813504709584242)\n"
     ]
    }
   ],
   "source": [
    "# Case/s reasonably chosen\n",
    "\n",
    "cases_reason_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case/s reasonably chosen'].iloc[i] == 'yes':\n",
    "        cases_reason_all += 1\n",
    "\n",
    "print('Case/s reasonably chosen: ', cases_reason_all, ' => ', cases_reason_all/all_len)\n",
    "print('')\n",
    "\n",
    "\n",
    "# single \n",
    "case_sel_single = 0\n",
    "\n",
    "for i in range(0, single_len):\n",
    "    if df_single['Case/s reasonably chosen'].iloc[i] == 'yes':\n",
    "        case_sel_single += 1\n",
    "\n",
    "print('single Case reasonably chosen: ', case_sel_single, ' => ', case_sel_single/single_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [16, 101]\n",
    "\n",
    "# my result\n",
    "my = [case_sel_single, single_len-case_sel_single]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"single stat/chi2 is \" + str(stat))\n",
    "print(\"single p value is \" + str(p))\n",
    "print(\"single dof is \" + str(dof))\n",
    "print(\"single expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "\n",
    "\n",
    "\n",
    "# multiple \n",
    "print('')\n",
    "case_sel_multiple = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Case/s reasonably chosen'].iloc[i] == 'yes':\n",
    "        case_sel_multiple += 1\n",
    "\n",
    "print('multiple Cases reasonably chosen: ', case_sel_multiple, ' => ', case_sel_multiple/multiple_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [24, 51]\n",
    "\n",
    "# my result\n",
    "my = [case_sel_multiple, multiple_len-case_sel_multiple]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"multiple stat/chi2 is \" + str(stat))\n",
    "print(\"multiple p value is \" + str(p))\n",
    "print(\"multiple dof is \" + str(dof))\n",
    "print(\"multiple expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "640e4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s defined:  35  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Case/s defined\n",
    "\n",
    "cases_def_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case/s defined'].iloc[i] == 'yes':\n",
    "        cases_def_all += 1\n",
    "\n",
    "print('Case/s defined: ', cases_def_all, ' => ', cases_def_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7616fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case/s\n",
    "\n",
    "cases = df['Case/s'].unique()\n",
    "#cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fba81e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit of analysis stated:  8  =>  0.22857142857142856\n",
      "\n",
      "stat/chi2 is 5.905964365733519\n",
      "p value is 0.015089702161222164\n",
      "dof is 1\n",
      "expected is [[ 18.46788991 164.53211009]\n",
      " [  3.53211009  31.46788991]]\n",
      "Dependent (reject H0)\n",
      "\n",
      "fisher is (0.27958579881656803, 0.012037015146544462)\n"
     ]
    }
   ],
   "source": [
    "# Unit of analysis stated\n",
    "\n",
    "uoa_stated_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Unit of analysis stated'].iloc[i] == 'yes':\n",
    "        uoa_stated_all += 1\n",
    "\n",
    "print('Unit of analysis stated: ', uoa_stated_all, ' => ', uoa_stated_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [14, 169]\n",
    "\n",
    "# my result\n",
    "my = [uoa_stated_all, all_len-uoa_stated_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1af4ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit of analysis\n",
    "\n",
    "uoa = df['Unit of analysis'].unique()\n",
    "#uoa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45526542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for choosing the unit of analysis:  15  =>  0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# Rationale for choosing the unit of analysis\n",
    "\n",
    "rationale_uoa_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Rationale for choosing the unit of analysis'].iloc[i] == 'yes':\n",
    "        rationale_uoa_all += 1\n",
    "\n",
    "print('Rationale for choosing the unit of analysis: ', rationale_uoa_all, ' => ', rationale_uoa_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fef35460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded:  30  =>  0.8571428571428571\n",
      "holistic:  5  =>  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Case design\n",
    "\n",
    "embedded_all = 0\n",
    "holistic_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case design'].iloc[i] == 'embedded':\n",
    "        embedded_all += 1\n",
    "    elif df['Case design'].iloc[i] == 'holistic':\n",
    "        holistic_all += 1\n",
    "\n",
    "print('embedded: ', embedded_all, ' => ', embedded_all/all_len)\n",
    "print('holistic: ', holistic_all, ' => ', holistic_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfa49031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale research site:  30  =>  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Rationale research site\n",
    "\n",
    "rationale_site_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Rationale research site'].iloc[i] == 'yes' or df['Rationale research site'].iloc[i] == 'yes, see case selection':\n",
    "        rationale_site_all += 1\n",
    "\n",
    "print('Rationale research site: ', rationale_site_all, ' => ', rationale_site_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "505226f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  24  =>  0.6857142857142857\n",
      "rough:  8  =>  0.22857142857142856\n"
     ]
    }
   ],
   "source": [
    "# Detail research site\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Detail research site'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Detail research site'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/all_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc46ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on-site:  29  =>  0.8285714285714286\n",
      "off-site:  3  =>  0.08571428571428572\n",
      "both:  3  =>  0.08571428571428572\n"
     ]
    }
   ],
   "source": [
    "# Research site\n",
    "\n",
    "on_all = 0\n",
    "off_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Research site'].iloc[i] == 'on-site':\n",
    "        on_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'off-site':\n",
    "        off_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'on-site, off-side':\n",
    "        both_all += 1\n",
    "\n",
    "print('on-site: ', on_all, ' => ', on_all/all_len)\n",
    "print('off-site: ', off_all, ' => ', off_all/all_len)\n",
    "print('both: ', both_all, ' => ', both_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b07e08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of a pilot case:  0  =>  0.0\n",
      "\n",
      "fisher is (inf, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Use of a pilot case\n",
    "\n",
    "pilot_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Use of a pilot case'].iloc[i] == 'yes':\n",
    "        pilot_all += 1\n",
    "\n",
    "print('Use of a pilot case: ', pilot_all, ' => ', pilot_all/all_len)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [4, 179]\n",
    "\n",
    "# my result\n",
    "my = [pilot_all, all_len-pilot_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78178137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site description:  24  =>  0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Site description\n",
    "\n",
    "site_descr_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Site description'].iloc[i] != 'not specified':\n",
    "        site_descr_all += 1\n",
    "\n",
    "print('Site description: ', site_descr_all, ' => ', site_descr_all/all_len)\n",
    "\n",
    "site_descr_unique = df['Site description'].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f35814e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case period:  19  =>  0.5428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Case period\n",
    "\n",
    "period_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case period '].iloc[i] != 'not specified':\n",
    "        period_all += 1\n",
    "\n",
    "print('Case period: ', period_all, ' => ', period_all/all_len)\n",
    "\n",
    "site_descr_unique = df['Case period '].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d16517a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal design:  12  =>  0.34285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Longitudinal design\n",
    "\n",
    "long_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Longitudinal design'].iloc[i] == 'yes':\n",
    "        long_all += 1\n",
    "\n",
    "print('Longitudinal design: ', long_all, ' => ', long_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81ed55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent on site (for data collection):  29  =>  0.8285714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['between 2 and 4 months', '13 months', 'not specified', '4 months',\n",
       "       '6 months', '12 months',\n",
       "       '8 months (5 months case A + 3 months case B)', '53 months',\n",
       "       '31 months', '23 days', '12 years', 'c. 1,5-2 years', '6 years',\n",
       "       '26 months', '11 months', '10 years', '5 years', '3 months',\n",
       "       '2 years', '2 months', '9 months', '22 months + during fall',\n",
       "       '18 months', '3 years', '11 years', '30 Monate'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time spent on site (for data collection)\n",
    "\n",
    "time_spent_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Time spent on site (for data collection)'].iloc[i] != 'not specified':\n",
    "        time_spent_all += 1\n",
    "\n",
    "print('Time spent on site (for data collection): ', time_spent_all, ' => ', time_spent_all/all_len)\n",
    "\n",
    "time_spent_unique = df['Time spent on site (for data collection)'].unique()\n",
    "time_spent_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05c6796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on-going:  14  =>  0.4\n",
      "retrospective:  10  =>  0.2857142857142857\n",
      "both:  10  =>  0.2857142857142857\n",
      "nature sum:  34  =>  0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Nature of data\n",
    "\n",
    "on_all = 0\n",
    "retro_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Nature of data'].iloc[i] == 'on-going':\n",
    "        on_all += 1\n",
    "    elif df['Nature of data'].iloc[i] == 'retrospective':\n",
    "        retro_all += 1\n",
    "    elif df['Nature of data'].iloc[i] == 'both':\n",
    "        both_all += 1\n",
    "\n",
    "print('on-going: ', on_all, ' => ', on_all/all_len)\n",
    "print('retrospective: ', retro_all, ' => ', retro_all/all_len)\n",
    "print('both: ', both_all, ' => ', both_all/all_len)\n",
    "print('nature sum: ', on_all+retro_all+both_all, ' => ', (on_all+retro_all+both_all)/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e620dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roles in team:  24  =>  0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Team-based research (data collection and analysis)\n",
    "\n",
    "team_roles_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if (df['Number of researchers conducting data collection'].iloc[i] != 'not specified' and df['Number of researchers conducting data analysis'].iloc[i] != 'not specified') or (df['Number of researchers conducting data collection'].iloc[i] == 'not specified' and df['Number of researchers conducting data analysis'].iloc[i] != 'not specified') or (df['Number of researchers conducting data collection'].iloc[i] != 'not specified' and df['Number of researchers conducting data analysis'].iloc[i] == 'not specified'):\n",
    "        team_roles_all += 1\n",
    "\n",
    "print('roles in team: ', team_roles_all, ' => ', team_roles_all/all_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ecca50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  3  =>  0.08571428571428572\n",
      "2:  7  =>  0.2\n",
      "3:  16  =>  0.45714285714285713\n",
      "4:  7  =>  0.2\n",
      "5:  1  =>  0.02857142857142857\n",
      "6:  1  =>  0.02857142857142857\n",
      "Team-based research:  32  =>  0.9142857142857143\n",
      "\n",
      "stat/chi2 is 4.881435820733435\n",
      "p value is 0.027147028241688333\n",
      "dof is 1\n",
      "expected is [[137.66972477  45.33027523]\n",
      " [ 26.33027523   8.66972477]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Number of authors (Team-based research)\n",
    "\n",
    "one_all = 0\n",
    "two_all = 0\n",
    "three_all = 0\n",
    "four_all = 0\n",
    "five_all = 0\n",
    "six_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Number of authors  '].iloc[i] == 1:\n",
    "        one_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 2:\n",
    "        two_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 3:\n",
    "        three_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 4:\n",
    "        four_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 5:\n",
    "        five_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 6:\n",
    "        six_all += 1\n",
    "\n",
    "print('1: ', one_all, ' => ', one_all/all_len)\n",
    "print('2: ', two_all, ' => ', two_all/all_len)\n",
    "print('3: ', three_all, ' => ', three_all/all_len)\n",
    "print('4: ', four_all, ' => ', four_all/all_len)\n",
    "print('5: ', five_all, ' => ', five_all/all_len)\n",
    "print('6: ', six_all, ' => ', six_all/all_len)\n",
    "print('Team-based research: ', all_len-one_all, ' => ', (all_len-one_all)/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [132, 51]\n",
    "\n",
    "# my result\n",
    "my = [all_len-one_all, one_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f73fcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Involvement of the researcher:  6  =>  0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Involvement of the researcher\n",
    "\n",
    "involved_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Involvement of the researcher'].iloc[i] == 'involved':\n",
    "        involved_all += 1\n",
    "\n",
    "print('Involvement of the researcher: ', involved_all, ' => ', involved_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a723d1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different roles for multiple investigators:  6  =>  0.17142857142857143\n",
      "\n",
      "stat/chi2 is 5.990617995832213\n",
      "p value is 0.014382162822009813\n",
      "dof is 1\n",
      "expected is [[ 11.75229358 171.24770642]\n",
      " [  2.24770642  32.75229358]]\n",
      "Dependent (reject H0)\n",
      "\n",
      "fisher is (0.22095238095238096, 0.012870884895002401)\n"
     ]
    }
   ],
   "source": [
    "# Different roles for multiple investigators\n",
    "\n",
    "diff_roles_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Different roles for multiple investigators'].iloc[i] == 'yes':\n",
    "        diff_roles_all += 1\n",
    "\n",
    "print('Different roles for multiple investigators: ', diff_roles_all, ' => ', diff_roles_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [8, 175]\n",
    "\n",
    "# my result\n",
    "my = [diff_roles_all, all_len-diff_roles_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc134e3",
   "metadata": {},
   "source": [
    "_**Data Collection**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecc39cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  31  =>  0.8857142857142857\n",
      "rough:  4  =>  0.11428571428571428\n",
      "\n",
      "stat/chi2 is 20.523732241015836\n",
      "p value is 5.889647715720123e-06\n",
      "dof is 1\n",
      "expected is [[119.20183486  63.79816514]\n",
      " [ 22.79816514  12.20183486]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data collection process \n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Elucidation of the data collection process '].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data collection process '].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/all_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [107, 76]\n",
    "\n",
    "# my result\n",
    "my = [detail_all+rough_all, all_len-(detail_all+rough_all)]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00317398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interviews :  32  =>  0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Interviews \n",
    "\n",
    "interviews_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Interviews '].iloc[i] == 'yes':\n",
    "        interviews_all += 1\n",
    "\n",
    "print('Interviews : ', interviews_all, ' => ', interviews_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a563dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi-structured:  19  =>  0.59375\n",
      "structured:  2  =>  0.0625\n"
     ]
    }
   ],
   "source": [
    "# Kind of interviews\n",
    "\n",
    "semi_all = 0\n",
    "struct_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Kind of interviews'].iloc[i] == 'semi-structured':\n",
    "        semi_all += 1\n",
    "    elif df_interv['Kind of interviews'].iloc[i] == 'structured':\n",
    "        struct_all += 1\n",
    "\n",
    "print('semi-structured: ', semi_all, ' => ', semi_all/interv_len)\n",
    "print('structured: ', struct_all, ' => ', struct_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "711ac7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:  2  =>  0.0625\n",
      "purposeful:  13  =>  0.40625\n",
      "snowball:  8  =>  0.25\n",
      "maximum variation:  20  =>  0.625\n"
     ]
    }
   ],
   "source": [
    "# Sampling strategy (interviews) (up to three)\n",
    "\n",
    "criterion_all = 0\n",
    "purposeful_all = 0\n",
    "snowball_all = 0\n",
    "variation_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if 'criterion' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        criterion_all += 1\n",
    "    if 'purposeful' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        purposeful_all += 1\n",
    "    if 'snowball' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        snowball_all += 1\n",
    "    if 'maximum variation' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        variation_all += 1\n",
    "\n",
    "print('criterion: ', criterion_all, ' => ', criterion_all/interv_len)\n",
    "print('purposeful: ', purposeful_all, ' => ', purposeful_all/interv_len)\n",
    "print('snowball: ', snowball_all, ' => ', snowball_all/interv_len)\n",
    "print('maximum variation: ', variation_all, ' => ', variation_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "914617f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviewees:  22  =>  0.6875\n"
     ]
    }
   ],
   "source": [
    "# Number of interviewees \n",
    "\n",
    "number_interviewees_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviewees '].iloc[i] != 'not specified':\n",
    "        number_interviewees_all += 1\n",
    "\n",
    "print('Number of interviewees: ', number_interviewees_all, ' => ', number_interviewees_all/interv_len)\n",
    "\n",
    "number_interviewees_unique = df_interv['Number of interviewees '].unique()\n",
    "#number_interviewees_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0abfd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviews:  24  =>  0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified', 20, 18, 38, 158, 84, 17, 25, 50, 31, 83, 69, 46,\n",
       "       49, 29, 57, 33, 39, 24, 23, 27], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of interviews\n",
    "\n",
    "number_interviews_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviews'].iloc[i] != 'not specified':\n",
    "        number_interviews_all += 1\n",
    "\n",
    "print('Number of interviews: ', number_interviews_all, ' => ', number_interviews_all/interv_len)\n",
    "\n",
    "number_interviews_unique = df_interv['Number of interviews'].unique()\n",
    "number_interviews_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c82fc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  8  =>  0.25\n",
      "concrete examples:  9  =>  0.28125\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  4  =>  0.125\n",
      "on request:  0  =>  0.0\n",
      "not specified:  11  =>  0.34375\n"
     ]
    }
   ],
   "source": [
    "# Use of an interview guide\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b23cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-test of interview guide:  1  =>  0.03125\n"
     ]
    }
   ],
   "source": [
    "# Pre-test of interview guide\n",
    "\n",
    "interv_guide_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Pre-test of interview guide'].iloc[i] == 'yes':\n",
    "        interv_guide_all += 1\n",
    "\n",
    "print('Pre-test of interview guide: ', interv_guide_all, ' => ', interv_guide_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca46a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview transcription:  28  =>  0.875\n"
     ]
    }
   ],
   "source": [
    "# Interview transcription\n",
    "\n",
    "interv_transcr_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview transcription'].iloc[i] == 'yes':\n",
    "        interv_transcr_all += 1\n",
    "\n",
    "print('Interview transcription: ', interv_transcr_all, ' => ', interv_transcr_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b49ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview review:  8  =>  0.25\n"
     ]
    }
   ],
   "source": [
    "# Interview review\n",
    "\n",
    "interv_review_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview review'].iloc[i] == 'yes':\n",
    "        interv_review_all += 1\n",
    "\n",
    "print('Interview review: ', interv_review_all, ' => ', interv_review_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cf7cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow up interviews:  6  =>  0.1875\n"
     ]
    }
   ],
   "source": [
    "# Follow up interviews\n",
    "\n",
    "interv_followup_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Follow up interviews'].iloc[i] == 'yes':\n",
    "        interv_followup_all += 1\n",
    "\n",
    "print('Follow up interviews: ', interv_followup_all, ' => ', interv_followup_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f57e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  20  =>  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Observation \n",
    "\n",
    "obers_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Observation '].iloc[i] == 'yes':\n",
    "        obers_all += 1\n",
    "\n",
    "print('Observation: ', obers_all, ' => ', obers_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57d54da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentation:  28  =>  0.8\n"
     ]
    }
   ],
   "source": [
    "# Documentation \n",
    "\n",
    "doc_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Documentation '].iloc[i] == 'yes':\n",
    "        doc_all += 1\n",
    "\n",
    "print('Documentation: ', doc_all, ' => ', doc_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "524c2285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionnaires:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires\n",
    "\n",
    "quest_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Questionnaires'].iloc[i] == 'yes':\n",
    "        quest_all += 1\n",
    "\n",
    "print('Questionnaires: ', quest_all, ' => ', quest_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "daa3d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  0  =>  0.0\n",
      "concrete examples:  0  =>  0.0\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  0  =>  0.0\n",
      "on request:  0  =>  0.0\n",
      "not specified:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires provided\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, quest_len):\n",
    "    if df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f33bb98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple data collection methods:  31  =>  0.8857142857142857\n",
      "use of all three qual. methods:  14  =>  0.4\n",
      "\n",
      "stat/chi2 is 1.3812821439446406\n",
      "p value is 0.23988287228827543\n",
      "dof is 1\n",
      "expected is [[85.90140845 21.09859155]\n",
      " [28.09859155  6.90140845]]\n",
      "Independent (H0 holds true)\n"
     ]
    }
   ],
   "source": [
    "# multiple data collection methods\n",
    "\n",
    "multiple_methods_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes'):\n",
    "        multiple_methods_all += 1\n",
    "\n",
    "print('multiple data collection methods: ', multiple_methods_all, ' => ', multiple_methods_all/all_len)\n",
    "\n",
    "\n",
    "three_qual_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes':\n",
    "        three_qual_all += 1\n",
    "\n",
    "print('use of all three qual. methods: ', three_qual_all, ' => ', three_qual_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [83, 24]\n",
    "\n",
    "# my result\n",
    "my = [multiple_methods_all, all_len-multiple_methods_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43bbcfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantitative:  0  =>  0.0\n",
      "qualitative:  33  =>  0.9428571428571428\n",
      "both:  2  =>  0.05714285714285714\n",
      "\n",
      "stat/chi2 is 7.663430189964011\n",
      "p value is 0.0056351267678752485\n",
      "dof is 1\n",
      "expected is [[26.37323944 80.62676056]\n",
      " [ 8.62676056 26.37323944]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Kind of data collected (Mix of qualitative and quantitative data)\n",
    "\n",
    "quantitative_all = 0\n",
    "qualitative_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Kind of data collected'].iloc[i] == 'quantitative':\n",
    "        quantitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'qualitative':\n",
    "        qualitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'both':\n",
    "        both_all += 1\n",
    "\n",
    "print('quantitative: ', quantitative_all, ' => ', quantitative_all/all_len)\n",
    "print('qualitative: ', qualitative_all, ' => ', qualitative_all/all_len)\n",
    "print('both: ', both_all, ' => ', both_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [33, 74]\n",
    "\n",
    "# my result\n",
    "my = [both_all, all_len-both_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fbb295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data triangulation:  22  =>  0.6285714285714286\n",
      "\n",
      "stat/chi2 is 10.792436941736007\n",
      "p value is 0.001019156252427995\n",
      "dof is 1\n",
      "expected is [[40.69014085 66.30985915]\n",
      " [13.30985915 21.69014085]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Data triangulation \n",
    "\n",
    "data_tri_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Data triangulation '].iloc[i] == 'yes':\n",
    "        data_tri_all += 1\n",
    "\n",
    "print('Data triangulation: ', data_tri_all, ' => ', data_tri_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [32, 75]\n",
    "\n",
    "# my result\n",
    "my = [data_tri_all, all_len-data_tri_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03439d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data collection:  2  =>  0.05714285714285714\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data collection\n",
    "\n",
    "researcher_tri_data_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Researcher triangulation during data collection'].iloc[i] == 'yes':\n",
    "        researcher_tri_data_all += 1\n",
    "\n",
    "print('Researcher triangulation during data collection: ', researcher_tri_data_all, ' => ', researcher_tri_data_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "306c4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data collection:  14  =>  0.4\n"
     ]
    }
   ],
   "source": [
    "# Number of researchers conducting data collection\n",
    "\n",
    "researchers_data_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Number of researchers conducting data collection'].iloc[i] != 'not specified':\n",
    "        researchers_data_all += 1\n",
    "\n",
    "print('Number of researchers conducting data collection: ', researchers_data_all, ' => ', researchers_data_all/all_len)\n",
    "\n",
    "researchers_data_unique = df['Number of researchers conducting data collection'].unique()\n",
    "#researchers_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4859d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study protocol:  4  =>  0.11428571428571428\n",
      "\n",
      "stat/chi2 is 1.049264906815325\n",
      "p value is 0.30567644616496864\n",
      "dof is 1\n",
      "expected is [[  6.78169014 100.21830986]\n",
      " [  2.21830986  32.78169014]]\n",
      "Independent (H0 holds true)\n",
      "\n",
      "fisher is (0.3799019607843137, 0.22405987362385774)\n"
     ]
    }
   ],
   "source": [
    "# Case study protocol\n",
    "\n",
    "protocol_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case study protocol'].iloc[i] == 'yes':\n",
    "        protocol_all += 1\n",
    "\n",
    "print('Case study protocol: ', protocol_all, ' => ', protocol_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [5, 102]\n",
    "\n",
    "# my result\n",
    "my = [protocol_all, all_len-protocol_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6baa78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study database:  4  =>  0.11428571428571428\n",
      "\n",
      "stat/chi2 is 0.6207221750212406\n",
      "p value is 0.43077904778650933\n",
      "dof is 1\n",
      "expected is [[ 7.53521127 99.46478873]\n",
      " [ 2.46478873 32.53521127]]\n",
      "Independent (H0 holds true)\n",
      "\n",
      "fisher is (0.4603960396039604, 0.26215215137769615)\n"
     ]
    }
   ],
   "source": [
    "# Case study database \n",
    "\n",
    "database_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Case study database '].iloc[i] == 'yes':\n",
    "        database_all += 1\n",
    "\n",
    "print('Case study database: ', database_all, ' => ', database_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [6, 101]\n",
    "\n",
    "# my result\n",
    "my = [database_all, all_len-database_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a387e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap of data collection and analysis:  11  =>  0.3142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Overlap of data collection and analysis\n",
    "\n",
    "overlap_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Overlap of data collection and analysis'].iloc[i] == 'yes':\n",
    "        overlap_all += 1\n",
    "\n",
    "print('Overlap of data collection and analysis: ', overlap_all, ' => ', overlap_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942570b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a093f90",
   "metadata": {},
   "source": [
    "_**Analysis**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f50a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  29  =>  0.8285714285714286\n",
      "rough:  5  =>  0.14285714285714285\n",
      "Elucidation of the data analysis process:  34  =>  0.9714285714285714\n",
      "\n",
      "stat/chi2 is 66.5660002860262\n",
      "p value is 3.3837233458642906e-16\n",
      "dof is 1\n",
      "expected is [[ 64.63761468 118.36238532]\n",
      " [ 12.36238532  22.63761468]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data analysis process\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Elucidation of the data analysis process'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data analysis process'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/all_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/all_len)\n",
    "print('Elucidation of the data analysis process: ', detail_all+rough_all, ' => ', (detail_all+rough_all)/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [43, 140]\n",
    "\n",
    "# my result\n",
    "my = [detail_all+rough_all, all_len-(detail_all+rough_all)]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3dd4f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field notes:  15  =>  0.42857142857142855\n",
      "\n",
      "stat/chi2 is 39.37990542450994\n",
      "p value is 3.4886869954982e-10\n",
      "dof is 1\n",
      "expected is [[ 20.14678899 162.85321101]\n",
      " [  3.85321101  31.14678899]]\n",
      "Dependent (reject H0)\n",
      "\n",
      "fisher is (0.06896551724137931, 3.133613116041653e-08)\n"
     ]
    }
   ],
   "source": [
    "# Field notes\n",
    "\n",
    "notes_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Field notes'].iloc[i] == 'yes':\n",
    "        notes_all += 1\n",
    "\n",
    "print('Field notes: ', notes_all, ' => ', notes_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [9, 174]\n",
    "\n",
    "# my result\n",
    "my = [notes_all, all_len-notes_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af627c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coding of raw data:  31  =>  0.8857142857142857\n",
      "\n",
      "stat/chi2 is 119.68308496528613\n",
      "p value is 7.421917603133727e-28\n",
      "dof is 1\n",
      "expected is [[ 36.09633028 146.90366972]\n",
      " [  6.90366972  28.09633028]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Coding of raw data\n",
    "\n",
    "code_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Coding of raw data'].iloc[i] == 'yes':\n",
    "        code_all += 1\n",
    "\n",
    "print('Coding of raw data: ', code_all, ' => ', code_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [12, 171]\n",
    "\n",
    "# my result\n",
    "my = [code_all, all_len-code_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5479f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  5  =>  0.16129032258064516\n",
      "complete in appendix:  6  =>  0.1935483870967742\n",
      "partially:  11  =>  0.3548387096774194\n",
      "on request:  0  =>  0.0\n",
      "no:  9  =>  0.2903225806451613\n"
     ]
    }
   ],
   "source": [
    "# Coding scheme available\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "partially_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding scheme available'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, partially':\n",
    "        partially_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'no':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/code_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/code_len)\n",
    "print('partially: ', partially_all, ' => ', partially_all/code_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/code_len)\n",
    "print('no: ', not_spec_all, ' => ', not_spec_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "943995ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of coding scheme:  3  =>  0.0967741935483871\n"
     ]
    }
   ],
   "source": [
    "# Validation of coding scheme\n",
    "\n",
    "validation_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Validation of coding scheme'].iloc[i] == 'yes':\n",
    "        validation_all += 1\n",
    "\n",
    "print('Validation of coding scheme: ', validation_all, ' => ', validation_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e1dcbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example codes available:  12  =>  0.3870967741935484\n"
     ]
    }
   ],
   "source": [
    "# Example codes available\n",
    "\n",
    "example_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Example codes available'].iloc[i] == 'yes':\n",
    "        example_all += 1\n",
    "\n",
    "print('Example codes available: ', example_all, ' => ', example_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6b98d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data analysis:  13  =>  0.37142857142857144\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data analysis\n",
    "\n",
    "researcher_tri_analysis_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Researcher triangulation during data analysis'].iloc[i] == 'yes':\n",
    "        researcher_tri_analysis_all += 1\n",
    "\n",
    "print('Researcher triangulation during data analysis: ', researcher_tri_analysis_all, ' => ', researcher_tri_analysis_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52a38837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data analysis:  17  =>  0.4857142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified', 'min. 2', 2, 1, 4, 3, '2 to 3'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of researchers conducting data analysis\n",
    "\n",
    "researchers_analysis_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Number of researchers conducting data analysis'].iloc[i] != 'not specified':\n",
    "        researchers_analysis_all += 1\n",
    "\n",
    "print('Number of researchers conducting data analysis: ', researchers_analysis_all, ' => ', researchers_analysis_all/all_len)\n",
    "\n",
    "researchers_analysis_unique = df['Number of researchers conducting data analysis'].unique()\n",
    "researchers_analysis_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6a69c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-rater reliability test :  3  =>  0.08571428571428572\n"
     ]
    }
   ],
   "source": [
    "# Inter-rater reliability test \n",
    "\n",
    "inter_rater_all = 0\n",
    "\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Inter-rater reliability test '].iloc[i] == 'yes':\n",
    "        inter_rater_all += 1\n",
    "\n",
    "print('Inter-rater reliability test : ', inter_rater_all, ' => ', inter_rater_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6111b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not specified', 0.743, 'multiple ratios (see detail)', 1],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inter-rater agreement ratio\n",
    "\n",
    "inter_ratio_unique = df['Inter-rater agreement ratio'].unique()\n",
    "inter_ratio_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1b5c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLAS-ti:  4  =>  0.12903225806451613\n",
      "Nvivo:  5  =>  0.16129032258064516\n",
      "not specified:  22  =>  0.7096774193548387\n"
     ]
    }
   ],
   "source": [
    "# Coding software\n",
    "\n",
    "atlas_all = 0\n",
    "nvivo_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding software'].iloc[i] == 'ATLAS-ti':\n",
    "        atlas_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'Nvivo':\n",
    "        nvivo_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('ATLAS-ti: ', atlas_all, ' => ', atlas_all/code_len)\n",
    "print('Nvivo: ', nvivo_all, ' => ', nvivo_all/code_len)\n",
    "print('not specified: ', no_all, ' => ', no_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "34c8bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicitly:  2  =>  0.05714285714285714\n",
      "implicitly:  10  =>  0.2857142857142857\n",
      "no:  23  =>  0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Data displays (technique)\n",
    "\n",
    "expl_all = 0\n",
    "impl_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Data displays (technique)'].iloc[i] == 'yes, explicitly':\n",
    "        expl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'yes, implicitly':\n",
    "        impl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('explicitly: ', expl_all, ' => ', expl_all/all_len)\n",
    "print('implicitly: ', impl_all, ' => ', impl_all/all_len)\n",
    "print('no: ', no_all, ' => ', no_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7bd54b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data displays:  35  =>  1.0\n",
      "\n",
      "stat/chi2 is 23.746512294298196\n",
      "p value is 1.0989433550560636e-06\n",
      "dof is 1\n",
      "expected is [[113.32568807  69.67431193]\n",
      " [ 21.67431193  13.32568807]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Data displays\n",
    "\n",
    "displays_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Data displays'].iloc[i] == 'yes':\n",
    "        displays_all += 1\n",
    "\n",
    "print('Data displays: ', displays_all, ' => ', displays_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [100, 83]\n",
    "\n",
    "# my result\n",
    "my = [displays_all, all_len-displays_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9eb2abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexible and opportunistic process:  2  =>  0.05714285714285714\n",
      "\n",
      "stat/chi2 is 0.1549474983840168\n",
      "p value is 0.6938514887927061\n",
      "dof is 1\n",
      "expected is [[  5.87614679 177.12385321]\n",
      " [  1.12385321  33.87614679]]\n",
      "Independent (H0 holds true)\n",
      "\n",
      "fisher is (0.46348314606741575, 0.31273952854271525)\n"
     ]
    }
   ],
   "source": [
    "# Flexible and opportunistic process\n",
    "\n",
    "flexible_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Flexible and opportunistic process'].iloc[i] == 'yes':\n",
    "        flexible_all += 1\n",
    "\n",
    "print('Flexible and opportunistic process: ', flexible_all, ' => ', flexible_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [5, 178]\n",
    "\n",
    "# my result\n",
    "my = [flexible_all, all_len-flexible_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eef63c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical chain of evidence:  34  =>  0.9714285714285714\n",
      "\n",
      "stat/chi2 is 79.09779826986579\n",
      "p value is 5.911016837735425e-19\n",
      "dof is 1\n",
      "expected is [[ 57.92201835 125.07798165]\n",
      " [ 11.07798165  23.92201835]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Logical chain of evidence\n",
    "\n",
    "evidence_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Logical chain of evidence'].iloc[i] == 'yes':\n",
    "        evidence_all += 1\n",
    "\n",
    "print('Logical chain of evidence: ', evidence_all, ' => ', evidence_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [35, 148]\n",
    "\n",
    "# my result\n",
    "my = [evidence_all, all_len-evidence_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7c69f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical testing (only explanatory):  1  =>  1.0\n",
      "\n",
      "fisher is (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Empirical testing (only explanatory)\n",
    "\n",
    "empir_test_all = 0\n",
    "\n",
    "for i in range(0, explan_len):\n",
    "    if df_explan['Empirical testing (only explanatory)'].iloc[i] == 'yes':\n",
    "        empir_test_all += 1\n",
    "\n",
    "print('Empirical testing (only explanatory): ', empir_test_all, ' => ', empir_test_all/explan_len)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [11, 6]\n",
    "\n",
    "# my result\n",
    "my = [empir_test_all, explan_len-empir_test_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "af4721f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation building (only exploratory):  31  =>  0.96875\n",
      "\n",
      "stat/chi2 is 12.655045465582905\n",
      "p value is 0.00037455348643691236\n",
      "dof is 1\n",
      "expected is [[39.55813953 14.44186047]\n",
      " [23.44186047  8.55813953]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Explanation building (only exploratory)\n",
    "\n",
    "explan_build_all = 0\n",
    "\n",
    "for i in range(0, explor_len):\n",
    "    if df_explor['Explanation building (only exploratory)'].iloc[i] == 'yes':\n",
    "        explan_build_all += 1\n",
    "\n",
    "print('Explanation building (only exploratory): ', explan_build_all, ' => ', explan_build_all/explor_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [32, 22]\n",
    "\n",
    "# my result\n",
    "my = [explan_build_all, explor_len-explan_build_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "554241a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series analysis (only explanatory):  1  =>  1.0\n",
      "\n",
      "fisher is (0.0, 0.16666666666666652)\n"
     ]
    }
   ],
   "source": [
    "# Time series analysis (only explanatory)\n",
    "\n",
    "time_series_all = 0\n",
    "\n",
    "for i in range(0, explan_len):\n",
    "    if df_explan['Time series analysis (only explanatory)'].iloc[i] == 'yes':\n",
    "        time_series_all += 1\n",
    "\n",
    "print('Time series analysis (only explanatory): ', time_series_all, ' => ', time_series_all/explan_len)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [2, 15]\n",
    "\n",
    "# my result\n",
    "my = [time_series_all, explan_len-time_series_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63933172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number explanatory single cases:  1\n",
      "Use of natural controls (only explanatory single CS):  0  =>  0.0\n",
      "\n",
      "fisher is (nan, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Use of natural controls (only explanatory single CS)\n",
    "\n",
    "# dataframe for explanatory single CS\n",
    "\n",
    "df_explan_single = df_explan.loc[df_explan['Number of cases'] == 1]\n",
    "explan_single_len = len(df_explan_single)\n",
    "print('Number explanatory single cases: ', explan_single_len)\n",
    "#df_single.head()\n",
    "\n",
    "\n",
    "natural_controls_all = 0\n",
    "\n",
    "for i in range(0, explan_single_len):\n",
    "    if df_explan_single['Use of natural controls (only explanatory single CS)'].iloc[i] == 'yes':\n",
    "        natural_controls_all += 1\n",
    "\n",
    "print('Use of natural controls (only explanatory single CS): ', natural_controls_all, ' => ', natural_controls_all/explan_single_len)\n",
    "\n",
    "\n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [0, 17]\n",
    "\n",
    "# my result\n",
    "my = [natural_controls_all, explan_len-natural_controls_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d5518e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for cross-case patterns (only multiple CS):  11  =>  0.9166666666666666\n",
      "\n",
      "stat/chi2 is 3.076097972972974\n",
      "p value is 0.07945092866381553\n",
      "dof is 1\n",
      "expected is [[48.18604651 25.81395349]\n",
      " [ 7.81395349  4.18604651]]\n",
      "Independent (H0 holds true)\n",
      "\n",
      "fisher is (0.14106583072100312, 0.04984347115109176)\n"
     ]
    }
   ],
   "source": [
    "# Search for cross-case patterns (only multiple CS)\n",
    "\n",
    "cross_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Search for cross-case patterns (only multiple CS)'].iloc[i] == 'yes':\n",
    "        cross_all += 1\n",
    "\n",
    "print('Search for cross-case patterns (only multiple CS): ', cross_all, ' => ', cross_all/multiple_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [45, 29]\n",
    "\n",
    "# my result\n",
    "my = [cross_all, multiple_len-cross_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')\n",
    "    \n",
    "# Fisher's exact test\n",
    "print('')\n",
    "\n",
    "print(\"fisher is \" + str(stats.fisher_exact(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "491822ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  34  =>  0.9714285714285714\n",
      "rough:  1  =>  0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "# Description of the observed world\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Description of the observed world'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Description of the observed world'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/all_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aeb80787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excerpts used:  32  =>  0.9142857142857143\n",
      "quotes:  32  =>  0.9142857142857143\n",
      "photograph:  1  =>  0.02857142857142857\n",
      "screenshots:  1  =>  0.02857142857142857\n",
      "blog:  1  =>  0.02857142857142857\n",
      "excerpts of raw data:  32  =>  0.9142857142857143\n",
      "\n",
      "stat/chi2 is 7.533514965226032\n",
      "p value is 0.006056163536783058\n",
      "dof is 1\n",
      "expected is [[ 53.72477064 129.27522936]\n",
      " [ 10.27522936  24.72477064]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Excerpts of raw data in case report\n",
    "\n",
    "excerpts_all = 0\n",
    "quotes_all = 0\n",
    "figures_all = 0\n",
    "screenshots_all = 0\n",
    "blog_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Excerpts of raw data in case report'].iloc[i] != 'no':\n",
    "        excerpts_all += 1\n",
    "\n",
    "print('excerpts used: ', excerpts_all, ' => ', excerpts_all/all_len)\n",
    "        \n",
    "for i in range(0, all_len):\n",
    "    if 'quotes' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        quotes_all += 1\n",
    "    if 'figures' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        figures_all += 1\n",
    "    if 'screenshots' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        screenshots_all += 1\n",
    "    if 'blog' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        blog_all += 1\n",
    "\n",
    "print('quotes: ', quotes_all, ' => ', quotes_all/all_len)\n",
    "print('photograph: ', figures_all, ' => ', figures_all/all_len)\n",
    "print('screenshots: ', screenshots_all, ' => ', screenshots_all/all_len)\n",
    "print('blog: ', blog_all, ' => ', blog_all/all_len)\n",
    "\n",
    "\n",
    "excerpts_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Excerpts of raw data in case report'].iloc[i] == 'no':\n",
    "        excerpts_all += 1\n",
    "\n",
    "print('excerpts of raw data: ', 35-excerpts_all, ' => ', (35-excerpts_all)/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [61, 122]\n",
    "\n",
    "# my result\n",
    "my = [excerpts_all, all_len-excerpts_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5418ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project reviews:  14  =>  0.4\n",
      "\n",
      "stat/chi2 is 10.665541735955605\n",
      "p value is 0.0010914987936343312\n",
      "dof is 1\n",
      "expected is [[ 34.41743119 148.58256881]\n",
      " [  6.58256881  28.41743119]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Project reviews\n",
    "\n",
    "project_review_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Project reviews'].iloc[i] == 'yes':\n",
    "        project_review_all += 1\n",
    "\n",
    "print('Project reviews: ', project_review_all, ' => ', project_review_all/all_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [27, 156]\n",
    "\n",
    "# my result\n",
    "my = [project_review_all, all_len-project_review_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8dfaad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with conflicting literature (only exploratory):  17  =>  0.53125\n",
      "\n",
      "stat/chi2 is 16.022406097436292\n",
      "p value is 6.259727427627159e-05\n",
      "dof is 1\n",
      "expected is [[14.44186047 39.55813953]\n",
      " [ 8.55813953 23.44186047]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Comparison with conflicting literature (only exploratory)\n",
    "\n",
    "confl_lit_all = 0\n",
    "\n",
    "for i in range(0, explor_len):\n",
    "    if df_explor['Comparison with conflicting literature (only exploratory)'].iloc[i] == 'yes':\n",
    "        confl_lit_all += 1\n",
    "\n",
    "print('Comparison with conflicting literature (only exploratory): ', confl_lit_all, ' => ', confl_lit_all/explor_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [6, 48]\n",
    "\n",
    "# my result\n",
    "my = [confl_lit_all, explor_len-confl_lit_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1d2e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison with similar literature (only exploratory):  30  =>  0.9375\n",
      "\n",
      "stat/chi2 is 24.275120241769542\n",
      "p value is 8.351080537495508e-07\n",
      "dof is 1\n",
      "expected is [[31.39534884 22.60465116]\n",
      " [18.60465116 13.39534884]]\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Comparison with similar literature (only exploratory)\n",
    "\n",
    "sim_lit_all = 0\n",
    "\n",
    "for i in range(0, explor_len):\n",
    "    if df_explor['Comparison with similar literature (only exploratory)'].iloc[i] == 'yes':\n",
    "        sim_lit_all += 1\n",
    "\n",
    "print('Comparison with similar literature (only exploratory): ', sim_lit_all, ' => ', sim_lit_all/explor_len)\n",
    "\n",
    "\n",
    "# chi2\n",
    "print('')\n",
    "\n",
    "# Dubé & Paré (2003)\n",
    "dp = [20, 34]\n",
    "\n",
    "# my result\n",
    "my = [sim_lit_all, explor_len-sim_lit_all]\n",
    "\n",
    "# defining the table\n",
    "data = [dp, my]\n",
    "stat, p, dof, expected = chi2_contingency(data)\n",
    "  \n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "print(\"stat/chi2 is \" + str(stat))\n",
    "print(\"p value is \" + str(p))\n",
    "print(\"dof is \" + str(dof))\n",
    "print(\"expected is \" + str(expected))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (H0 holds true)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29894814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1107cb0",
   "metadata": {},
   "source": [
    "_**Miscellaneous**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "395b86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key case study characteristics summarized :  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Key case study characteristics summarized \n",
    "\n",
    "cs_charact_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Key case study characteristics summarized '].iloc[i] == 'yes':\n",
    "        cs_charact_all += 1\n",
    "\n",
    "print('Key case study characteristics summarized : ', cs_charact_all, ' => ', cs_charact_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e90752cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methodological literature cited:  35  =>  1.0\n",
      "Allison:  1\n",
      "Alvesson:  1\n",
      "Bala, H., Venkatesh:  1\n",
      "Barley:  1\n",
      "Barrett, M., Oborn:  1\n",
      "Bechky, B., Okhuysen:  1\n",
      "Benbasat, I., Goldstein, D., Mead, M., 1987:  5\n",
      "Benbasat, I., Goldstein, D., Mead, M., 1997:  1\n",
      "Biernacki, P., Waldorf:  1\n",
      "Birks, D., Fern:  2\n",
      "Blei, D., 2012:  1\n",
      "Bowen, G., 2006:  1\n",
      "Bowen, G., 2008:  1\n",
      "Boyatzis, R., 1998:  2\n",
      "Bryant, A., Charmaz:  1\n",
      "urton-Jones, A., McLean:  1\n",
      "Chan, Y., Reich:  1\n",
      "Charmaz, K., 2006:  5\n",
      "Charmaz, K., 2014:  1\n",
      "Corbin, J., Strauss, A., 1990:  6\n",
      "Corbin, J., Strauss, A., 2008:  1\n",
      "Creswell, J., Clark:  1\n",
      "Darke, P., Shanks:  1\n",
      "Denzin, N., 1997:  1\n",
      "Denzin, N., Lincoln:  1\n",
      "Dube, L., Pare:  4\n",
      "Easterby-Smith, M., Thorpe:  1\n",
      "Edmondson, A., McManus:  1\n",
      "Eisenhardt, K., 1989:  11\n",
      "Eisenhardt, K., 2000:  1\n",
      "Eisenhardt, K., Graebner:  5\n",
      "Elbanna, A., 2010:  1\n",
      "Elsbach, K., Sutton:  1\n",
      "Gerring, J., 2006:  1\n",
      "Gerring, J., 2007:  4\n",
      "Gersick, C., 1991:  1\n",
      "Ghazawneh, A., Henfridsson:  1\n",
      "Gibbert, M., Ruigrok, W., 2010:  1\n",
      "Gibbert, M., Ruigrok, W., Wicki, B., 2008:  2\n",
      "Gimpel, K., Schneider:  1\n",
      "Gioia, D., Corley:  1\n",
      "Glaser, B., 1978:  3\n",
      "Glaser, B., Strauss:  3\n",
      "Goetz, J., LeCompte:  1\n",
      "Golden, B., 1992:  1\n",
      "Golsorkhi, D., Rouleau:  1\n",
      "Gregor, S., 2006:  1\n",
      "Gregory, R., Beck:  1\n",
      "Gregory, R., Keil, M., 2014:  1\n",
      "Gregory, R., Keil, M., Muntermann:  1\n",
      "Guillemette, M., Pare:  1\n",
      "Huang, J., Pan:  1\n",
      "Huber, G., Power:  1\n",
      "Huberman, A., Miles:  1\n",
      "Jarzabkowski, P., 2005:  1\n",
      "Jarzabkowski, P., 2010:  1\n",
      "Johns, G., 2006:  1\n",
      "Kaplan, S., 2008:  1\n",
      "Katz, E., Haas:  1\n",
      "Keil, T., 2002:  1\n",
      "Kelly, G., 1955:  1\n",
      "Kirsch, L., 2004:  1\n",
      "Kirsh, D., Maglio:  1\n",
      "Klein, H., Myers:  4\n",
      "Krippendorff, K., 2004:  1\n",
      "Kuzel, A., 1992:  1\n",
      "Langley, A., 1999:  9\n",
      "Lee, A., 1989:  2\n",
      "Lee, A., Baskerville:  1\n",
      "Lee, J., Berente:  1\n",
      "Leonardi, P., 2013:  1\n",
      "Lincoln, Y., Guba:  1\n",
      "Locke, K., Golden:  1\n",
      "Mantere, S., Ketokivi:  1\n",
      "Markus, M., 1989:  1\n",
      "Mays, N., Pope:  1\n",
      "Miles, M., Huberman:  9\n",
      "Miles, R., Snow:  1\n",
      "Miller, C., Cardinal:  1\n",
      "Mimno, D., McCallum:  1\n",
      "Mingers, J., 2014:  1\n",
      "Mingers, J., Willcocks, L., 2014:  1\n",
      "Mingers, J., Willcocks, L., 2017:  1\n",
      "Montealegre, R., 2002:  2\n",
      "Myers, M., 1997:  1\n",
      "Myers, M., 2009:  1\n",
      "Myers, M., Newman:  1\n",
      "Ngwenyama, O., Klein:  1\n",
      "Niiniluoto, I., 1999:  1\n",
      "Pan, S., Tan:  5\n",
      "Pare, G., 2004:  2\n",
      "Patton, M., 1990:  1\n",
      "Patton, M., 2002:  2\n",
      "Pentland, B., 1999:  2\n",
      "Pettigrew, A., 1990:  1\n",
      "Pickering, A., 1993:  1\n",
      "Poole, M., Lambert:  2\n",
      "Pratt, M., 2008:  1\n",
      "Reich, B., Benbasat:  1\n",
      "Reynolds, T., Gutman:  1\n",
      "Rubin, H., Rubin:  1\n",
      "Sabherwal, R., Chan, Y., 2001:  1\n",
      "Sabherwal, R., Robey, D., 1995:  1\n",
      "Sarker, S., Sarker:  1\n",
      "Schultze, U., Avital:  1\n",
      "Seidel, S., Recker:  1\n",
      "Siggelkow, N., 2007:  2\n",
      "Spradley, J., 1979:  1\n",
      "Strauss, A., Corbin:  4\n",
      "Street, C., Ward:  1\n",
      "Strong, D., Volkoff:  1\n",
      "Tan, B., Pan:  1\n",
      "Tsang, E., 2014:  1\n",
      "Urquhart, C., 2013:  1\n",
      "Urquhart, C., Lehmann:  1\n",
      "Uys, J., Du Preez:  1\n",
      "Van de Ven, A., 1992:  1\n",
      "Van de Ven, A., 2007:  2\n",
      "Van de Ven, A., Poole:  1\n",
      "Venkatesh, V., Brown:  1\n",
      "Voss, C., Tsikriktsis:  1\n",
      "Walsh, I., Holton:  1\n",
      "Walsham, G., 2006:  4\n",
      "Weick, K., 1995:  1\n",
      "Yin, R., 1984:  1\n",
      "Yin, R., 1994. App:  1\n",
      "Yin, R., 1994. Case:  5\n",
      "Yin, R., 2002. Case:  1\n",
      "Yin, R., 2003. Case:  5\n",
      "Yin, R., 2009. Case:  7\n",
      "Yin, R., 2014. Case:  2\n",
      "Yin, R., 2015. Qual:  1\n",
      "Yoo, Y., Henfridsson:  1\n"
     ]
    }
   ],
   "source": [
    "# Methodological literature cited\n",
    "# note: for this analysis the cited methodological litertur style was standardized in the excel file (oriented to JSIS\n",
    "# bibliography style + first names of the authors limited to first character of the name and no accents on characters)\n",
    "\n",
    "methodol_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Methodological literature cited'].iloc[i] == 'yes':\n",
    "        methodol_all += 1\n",
    "\n",
    "print('Methodological literature cited: ', methodol_all, ' => ', methodol_all/all_len)\n",
    "\n",
    "\n",
    "# sum of each methodological literature cited\n",
    "\n",
    "#Allison, G., 1971. Essence of Decision\n",
    "allison = 0\n",
    "#Alvesson, M., and Sköldberg, K. 2009. Reflexive Methodology:\n",
    "alvesson = 0\n",
    "#Bala, H., Venkatesh, V., 2007. Assimilation of interorganizational business process standards\n",
    "bala = 0\n",
    "#Barley, S., 1996. Technicians in the Workplace: Ethnographic\n",
    "barley = 0\n",
    "#Barrett, M., Oborn, E., Orlikowski, W., Yates, J., 2012. Reconfiguring Boundary Relations: Robotic Innovations in Pharmacy Work,”\n",
    "barrett = 0\n",
    "#Bechky, B., Okhuysen, G., 2011. Expecting the Unexpected? How SWAT Officers and Film Crews Handle\n",
    "bechky = 0\n",
    "#Benbasat, I., Goldstein, D., Mead, M., 1987. The case research strategy in studies of information system\n",
    "benbasat_1987 = 0\n",
    "#Benbasat, I., Goldstein, D., Mead, M., 1997. The case research strategy in studies of information systems\n",
    "benbasat_1997 = 0\n",
    "#Biernacki, P., Waldorf, D., 1981. Snowball sampling: problem and techniques of chain referral sampling\n",
    "biernacki = 0\n",
    "#Birks, D., Fernandez, W., Levina, N., Nasirin, S., 2013. Grounded theory method in information systems research\n",
    "birks = 0\n",
    "#Blei, D., 2012. Probabilistic topic models\n",
    "blei = 0\n",
    "#Bowen, G., 2006. Grounded Theory and Sensitizing Concepts,”\n",
    "bowen_2006 = 0\n",
    "#Bowen, G., 2008. Grounded theory and sensitizing concepts\n",
    "bowen_2008 = 0\n",
    "#Boyatzis, R., 1998. Transforming Qualitative Information: Thematic Analysis and Code Development\n",
    "boyatzis = 0\n",
    "#Bryant, A., Charmaz, K., 2007. The Sage Handbook of Grounded Theory\n",
    "bryant = 0\n",
    "#Burton-Jones, A., McLean, E., and Monod, E., 2015. Theoretical Perspectives in IS Research: From Variance and Process to\n",
    "burton = 0\n",
    "#Chan, Y., Reich, B., 2007. IT alignment: what have we learned?\n",
    "chan = 0\n",
    "#Charmaz, K., 2006. Constructing Grounded Theory: A Practical Guide Through Qualitative Research\n",
    "charmaz_2006 = 0\n",
    "#Charmaz, K., 2014. Constructing Grounded Theory\n",
    "charmaz_2014 = 0\n",
    "#Corbin, J., Strauss, A., 1990. Grounded theory research: procedures, canons, and evaluative criteria\n",
    "corbin_1990 = 0\n",
    "#Corbin, J., Strauss, A., 2008. Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory\n",
    "corbin_2008 = 0\n",
    "#Creswell, J., Clark, V., 2007. Designing and Conducting Mixed Methods Research\n",
    "creswell = 0\n",
    "#Darke, P., Shanks, G., Broadbent, M., 1998. Successfully completing case study research: combining rigour, relevance and pragmatism\n",
    "darke = 0\n",
    "#Denzin, N., 1997. Interpretive Ethnography: Ethnographic Practices for the 21st Century\n",
    "denzin_1997 = 0\n",
    "#Denzin, N., Lincoln, Y., 2000. Handbook of Qualitative Research\n",
    "denzin_2000 = 0\n",
    "#Dube, L., Pare, G., 2003. Rigor in information systems positivist case research: current practices, trends, and recommendations\n",
    "dube = 0\n",
    "#Easterby-Smith, M., Thorpe, R., Lowe, A., 1991. Management Research: An Introduction\n",
    "easterby = 0\n",
    "#Edmondson, A., McManus, S., 2007. Methodological Fit in Management Field Research,”\n",
    "edmonson = 0\n",
    "#Eisenhardt, K., 1989. Building theories from case study research\n",
    "eisen_1989 = 0\n",
    "#Eisenhardt, K., 2000. Paradox, Spirals, Ambivalence: The New Language of Change and Pluralism,”\n",
    "eisen_2000 = 0\n",
    "#Eisenhardt, K., Graebner, M., 2007. Theory building from cases: opportunities and challenges\n",
    "eisen_2007 = 0\n",
    "#Elbanna, A., 2010. Rethinking IS Project Boundaries in Practice:\n",
    "elbanna = 0\n",
    "#Elsbach, K., Sutton, R., 1992. Acquiring organizational legitimacy through illegitimate actions: a marriage of institutional and impression management theories\n",
    "elsbach = 0\n",
    "#Gerring, J., 2006. Case Study Research: Principles and Practices\n",
    "gerring_2006 = 0\n",
    "#Gerring, J., 2007. Case Study Research: Principles and Practices\n",
    "gerring_2007 = 0\n",
    "#Gersick, C., 1991. Revolutionary Change Theories: A Multilevel\n",
    "gersick = 0\n",
    "#Ghazawneh, A., Henfridsson, O., 2013. Balancing Platform Control and External Contribution in Third-Party Development:\n",
    "ghazawneh = 0\n",
    "#Gibbert, M., Ruigrok, W., 2010. The what and how of case study rigor: three strategies based on published work\n",
    "gibbert_2010 = 0\n",
    "#Gibbert, M., Ruigrok, W., Wicki, B., 2008. What Passes as a Rigorous Case Study?,”\n",
    "gibbert_2008 = 0\n",
    "#Gimpel, K., Schneider, N., O'Connor, B., Das, D., Mills, D., Eisenstein, J., Heilman, M., Yogatama, D., Flanigan, J., Smith, N., 2011. Part-of-speech tagging for twitter\n",
    "gimpel = 0\n",
    "#Gioia, D., Corley, K., and Hamilton, A., 2013. Seeking Qualitative Rigor in Inductive Research: Notes on the Gioia Methodology,”\n",
    "gioia = 0\n",
    "#Glaser, B., 1978. Theoretical Sensitivity: Advances in the Methodology of Grounded \n",
    "glaser_1978 = 0\n",
    "#Glaser, B., Strauss, A., 1967. The Discovery of Grounded Theory: Strategies for Qualitative Research\n",
    "glaser_1967 = 0\n",
    "#Goetz, J., LeCompte, M., 1984. Ethnography and Qualitative Design in Educational Research\n",
    "goetz = 0\n",
    "#Golden, B., 1992. The past is the past – or is it? The use of retrospective accounts of past strategy\n",
    "golden = 0\n",
    "#Golsorkhi, D., Rouleau, L., Seidl, D., Vaara, E. (Eds.), 2010. Cambridge Handbook of Strategy as Practice\n",
    "golsorkhi = 0\n",
    "#Gregor, S., 2006. The Nature of Theory in Information Systems,”\n",
    "gregor = 0\n",
    "#Gregory, R., Beck, R., Keil, M., 2013. Control balancing in information systems development offshoring projects\n",
    "gregory_2013 = 0\n",
    "#Gregory, R., Keil, M., 2014. Blending bureaucratic and collaborative management styles to achieve control ambidexterity in IS projects\n",
    "gregory_2014 = 0\n",
    "#Gregory, R., Keil, M., Muntermann, J., Mähring, M., 2015. “Paradoxes and the Nature of Ambidexterity in IT Transformation\n",
    "gregory_2015 = 0\n",
    "#Guillemette, M., Pare, G., 2012. Transformation of the Information Technology Function in Organizations:\n",
    "guill = 0\n",
    "#Huang, J., Pan, S., Liu, J., 2017. Boundary permeability and online-offline hybrid organization: a case study of Suning\n",
    "huang = 0\n",
    "#Huber, G., Power, D., 1985. Retrospective Reports of Strategic Level Managers: Guidelines for Increasing Their\n",
    "huber = 0\n",
    "#Huberman, A., Miles, M., 1994. Data management and analysis methods\n",
    "huberman = 0\n",
    "#Jarzabkowski, P., 2005. Strategy as Practice: An Activity-based Approach\n",
    "jarz_2005 = 0\n",
    "#Jarzabkowski, P., 2010. An activity-theory approach to Strategy as Practice\n",
    "jarz_2010 = 0\n",
    "#Johns, G., 2006. The Essential Impact of Context on Organizational Behavior,”\n",
    "johns = 0\n",
    "#Kaplan, S., 2008. Framing contests: strategy making under uncertainty\n",
    "kaplan = 0\n",
    "#Katz, E., Haas, H., Gurevitch, M., 1973. On the Use of the Mass Media for Important Things,”\n",
    "katz = 0\n",
    "#Keil, T., 2002. External Corporate Venturing: Strategic Renewal in Rapidly Changing Industries\n",
    "keil = 0\n",
    "#Kelly, G., 1955. The Psychology of Personal ConstructsPettigrew, A.M., 1990. Longitudinal field research on change: theory and practice\n",
    "kelly = 0\n",
    "#Kirsch, L., 2004. Deploying Common Systems Globally:\n",
    "kirsch = 0\n",
    "#Kirsh, D., Maglio, P., 1994. On Distinguishing Epistemic from\n",
    "kirsh = 0\n",
    "#Klein, H., Myers, M., 1999. A set of principles for conducting and evaluating interpretive field studies in information systems\n",
    "klein = 0\n",
    "#Krippendorff, K., 2004. Content Analysis: An Introduction to Its Methodology\n",
    "krippe = 0\n",
    "#Kuzel, A., 1992. Sampling in Qualitative Inquiry,”\n",
    "kuzel = 0\n",
    "#Langley, A., 1999. Strategies for theorizing from process data\n",
    "langley = 0\n",
    "#Lee, A., 1989. A scientific methodology for MIS case studies\n",
    "lee_1989 = 0\n",
    "#Lee, A., Baskerville, R., 2003. Generalizing Generalizability in Information Systems Research,”\n",
    "lee_2003 = 0\n",
    "#Lee, J., Berente, N., 2012. Digital Innovation and the Division of Innovative Labor: Digital Controls in the Automotive Industry\n",
    "lee_2012 = 0\n",
    "#Leonardi, P., 2013. When does technology use enable network change in organizations? A comparative study of feature use and shared affordance\n",
    "leonardi = 0\n",
    "#Lincoln, Y., Guba, E., 1985. Naturalistic Inquiry\n",
    "lincoln = 0\n",
    "#Locke, K., Golden-Biddle, K., Feldman, M., 2008. Making Doubt Generative: Rethinking the Role of Doubt in the Research Process\n",
    "locke = 0\n",
    "#Mantere, S., Ketokivi, M., 2013. Reasoning in Organization Science,”\n",
    "mantere = 0\n",
    "#Markus, M., 1989. Case Selection in a Disconfirmatory Case\n",
    "markus = 0\n",
    "#Mays, N., Pope, C., 1995. Rigour and qualitative research\n",
    "mays = 0\n",
    "#Miles, M., Huberman, A., 1994. Qualitative Data Analysis: An Expanded Sourcebook\n",
    "miles_1994 = 0\n",
    "#Miles, R., Snow, C., Meyer, A., Coleman, H., 1978. Organizational strategy, structure, and process\n",
    "miles_1978 = 0\n",
    "#Miller, C., Cardinal, L., Glick, W., 1997. Retrospective Reports in Organizational Research: A Reexamination of\n",
    "miller = 0\n",
    "#Mimno, D., McCallum, A., 2007. Mining a digital library for influential authors\n",
    "mimno = 0\n",
    "#Mingers, J., 2014. Guidelines for Conducting Semiotic Research in Information Systems,”\n",
    "mingers = 0\n",
    "#Mingers, J., Willcocks, L., 2014. An Integrative Semiotic Framework for Information Systems: \n",
    "mingers_will_2014 = 0\n",
    "#Mingers, J., Willcocks, L., 2017. An Integrative Semiotic Methodology for Is Research,”\n",
    "mingers_will_2017 = 0\n",
    "#Montealegre, R., 2002. A process model of capability development: lessons from the electronic commerce strategy at Bolsa de Valores de Guayaquil\n",
    "monte = 0\n",
    "#Myers, M., 1997. Qualitative research in information systems\n",
    "myers_1997 = 0\n",
    "#Myers, M., 2009. Qualitative Research in Business & Management\n",
    "myers_2009 = 0\n",
    "#Myers, M., Newman, M., 2007. The qualitative interview in IS research: examining the craft\n",
    "myers_2007 = 0\n",
    "#Ngwenyama, O., Klein, S., 2018. Phronesis, argumentation and puzzle solving in IS research: illustrating an approach to phronetic IS research practice\n",
    "ngwenyama = 0\n",
    "#Niiniluoto, I., 1999. Defending Abduction\n",
    "nii = 0\n",
    "#Pan, S., Tan, B., 2011. Demystifying case research: a structured pragmatic situational (SPS) approach to conducting case studies\n",
    "pan = 0\n",
    "#Pare, G., 2004. Investigating information systems with positivist case research\n",
    "pare = 0\n",
    "#Patton, M., 1990. Qualitative Evaluation and Research Methods\n",
    "patton_1990 = 0\n",
    "#Patton, M., 2002. Qualitative Research and Evaluation Methods\n",
    "patton_2002 = 0\n",
    "#Pentland, B., 1999. Building process theory with narrative: from description to explanation\n",
    "pentland = 0\n",
    "#Pettigrew, A., 1990. Longitudinal field research on change: theory and practice\n",
    "pettigrew = 0\n",
    "#Pickering, A., 1993. The Mangle of Practice: Agency and Emergence\n",
    "pick = 0\n",
    "#Poole, M., Lambert, N., Murase, T., Asencio, R., McDonald, J., 2016. Sequential analysis of processes\n",
    "poole = 0\n",
    "#Pratt, M., 2008. Fitting oval pegs into round holes: tensions in evaluating and publishing qualitative research in top-tier American journals\n",
    "pratt = 0\n",
    "#Reich, B., Benbasat, I., 1996. Measuring the linkage between business and information technology objectives\n",
    "reich = 0\n",
    "#Reynolds, T., Gutman, J., 1988. Laddering Theory, Method, Analysis, and Interpretation\n",
    "reynolds = 0\n",
    "#Rubin, H., Rubin, I., 2005. Qualitative Interviewing: The Art of Hearing Data\n",
    "rubin = 0\n",
    "#Sabherwal, R., Chan, Y., 2001. Alignment between business and IS strategies: a study of prospectors, analyzers, and defenders\n",
    "sab_2001 = 0\n",
    "#Sabherwal, R., Robey, D., 1995. Reconciling Variance and Process Strategies for Studying Information System Development,”\n",
    "sab_1995 = 0\n",
    "#Sarker, S., Sarker, A., Sahaym, S., Bjørn-Andersen, N., 2012. Exploring value cocreation in relationships between an ERP vendor and its partners: a revelatory case\n",
    "sarker = 0\n",
    "#Schultze, U., Avital, M., 2011. Designing Interviews to Generate Rich Data for Information Systems Research\n",
    "schultze = 0\n",
    "#Seidel, S., Recker, J., vom Brocke, J., 2013. Sensemaking and sustainable practicing: functional affordances of information systems in green transformations\n",
    "seidel = 0\n",
    "#Siggelkow, N., 2007. Persuasion with case studies\n",
    "siggelkow = 0\n",
    "#Spradley, J., 1979. The Ethnographic Interview\n",
    "spradley = 0\n",
    "#Strauss, A., Corbin, J., 1998. Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory\n",
    "strauss = 0\n",
    "#Street, C., Ward, K., 2012. Improving validity and reliability in longitudinal case study timelines\n",
    "street = 0\n",
    "#Strong, D., Volkoff, O., Johnson, S., Pelletier, L., Tulu, B., Bar-On, I., Trudel, J., Garber, L., 2014. A theory of organization-EHR affordance actualization\n",
    "strong = 0\n",
    "#Tan, B., Pan, S., Hackney, R., 2010. The strategic implications of web technologies: a process model of how web technologies enhance organizational\n",
    "tan = 0\n",
    "#Tsang, E., 2014. Case studies and generalization in information systems research: A critical realist perspective\n",
    "tsang = 0\n",
    "#Urquhart, C., 2013. Grounded Theory for Qualitative Research\n",
    "ur_2013 = 0\n",
    "#Urquhart, C., Lehmann, H., Myers, M., 2010. Putting the ‘theory’back into grounded theory: guidelines for grounded theory studies in information systems\n",
    "ur_2010 = 0\n",
    "#Uys, J., Du Preez, N., Uys, E., 2008. Leveraging unstructured information using topic modelling\n",
    "uys = 0\n",
    "#Van de Ven, A., 1992. Suggestions for Studying Strategy\n",
    "ven_1992 = 0\n",
    "#Van de Ven, A., 2007. Engaged Scholarship: A Guide for Organizational and Social Research\n",
    "ven_2007 = 0\n",
    "#Van de Ven, A., Poole, M., 1995. Explaining Development and Change in Organizations\n",
    "ven_1995 = 0\n",
    "#Venkatesh, V., Brown, S., Bala, H., 2013. Bridging the Qualitative-Quantitative Divide : Guidelines for Conducting\n",
    "venka = 0\n",
    "#Voss, C., Tsikriktsis, N., Frohlich, M., 2002. Case research in operations management\n",
    "voss = 0\n",
    "#Walsh, I., Holton, J., Bailyn, L., Fernandez, W., Levina, N., and Glaser, B., 2015. What Grounded Theory Is … A Critically\n",
    "walsh = 0\n",
    "#Walsham, G., 2006. Doing interpretive research\n",
    "walsham = 0\n",
    "#Weick, K., 1995. Sensemaking in Organizations\n",
    "weick = 0\n",
    "#Yin, R., 1984. Case Study Research\n",
    "yin_1984 = 0\n",
    "#Yin, R., 1994. Applications of Case Study Research\n",
    "yin_1994a = 0\n",
    "#Yin, R., 1994. Case Study Research: Design and Methods\n",
    "yin_1994b = 0\n",
    "#Yin, R., 2002. Case Study Research: Design and Methods\n",
    "yin_2002 = 0\n",
    "#Yin, R., 2003. Case Study Research: Design and Methods\n",
    "yin_2003 = 0\n",
    "#Yin, R., 2009. Case Study Research: Design and Methods\n",
    "yin_2009 = 0\n",
    "#Yin, R., 2014. Case Study Research: Design and Methods\n",
    "yin_2014 = 0\n",
    "#Yin, R., 2015. Qualitative Research from Start to Finish\n",
    "yin_2015 = 0\n",
    "#Yoo, Y., Henfridsson, O., Lyytinen, K., 2010. The New Organizing Logics of Digital Innovation: An Agenda for Information Systems Research\n",
    "yoo = 0\n",
    "\n",
    "\n",
    "for i in range(0, all_len):       \n",
    "    if 'Allison' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        allison += 1\n",
    "    if 'Alvesson' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        alvesson += 1\n",
    "    if 'Bala, H., Venkatesh' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        bala += 1\n",
    "    if 'Barley, S., 1996' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        barley += 1    \n",
    "    if 'Barrett, M., Oborn' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        barrett += 1\n",
    "    if 'Bechky, B., Okhuysen' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        bechky += 1   \n",
    "    if 'Benbasat, I., Goldstein, D., Mead, M., 1987' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        benbasat_1987 += 1    \n",
    "    if 'Benbasat, I., Goldstein, D., Mead, M., 1997' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        benbasat_1997 += 1\n",
    "    if 'Biernacki, P., Waldorf' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        biernacki += 1    \n",
    "    if 'Birks, D., Fern' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        birks += 1\n",
    "    if 'Blei, D., 2012' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        blei += 1        \n",
    "    if 'Bowen, G., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        bowen_2006 += 1        \n",
    "    if 'Bowen, G., 2008' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        bowen_2008 += 1        \n",
    "    if 'Boyatzis, R., 1998' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        boyatzis += 1        \n",
    "    if 'Bryant, A., Charmaz' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        bryant += 1        \n",
    "    if 'Burton-Jones, A., McLean' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        burton += 1        \n",
    "    if 'Chan, Y., Reich' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        chan += 1        \n",
    "    if 'Charmaz, K., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        charmaz_2006 += 1        \n",
    "    if 'Charmaz, K., 2014' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        charmaz_2014 += 1        \n",
    "    if 'Corbin, J., Strauss, A., 1990' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        corbin_1990 += 1        \n",
    "    if 'Corbin, J., Strauss, A., 2008' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        corbin_2008 += 1\n",
    "    if 'Creswell, J., Clark' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        creswell += 1\n",
    "    if 'Darke, P., Shanks' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        darke += 1 \n",
    "    if 'Denzin, N., 1997' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        denzin_1997 += 1 \n",
    "    if 'Denzin, N., Lincoln' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        denzin_2000 += 1         \n",
    "    if 'Dube, L., Pare' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        dube += 1 \n",
    "    if 'Easterby-Smith, M., Thorpe' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        easterby += 1         \n",
    "    if 'Edmondson, A., McManus' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        edmonson += 1         \n",
    "    if 'Eisenhardt, K., 1989' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        eisen_1989 += 1 \n",
    "    if 'Eisenhardt, K., 2000' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        eisen_2000 += 1         \n",
    "    if 'Eisenhardt, K., Graebner' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        eisen_2007 += 1         \n",
    "    if 'Elbanna, A., 2010' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        elbanna += 1         \n",
    "    if 'Elsbach, K., Sutton' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        elsbach += 1         \n",
    "    if 'Gerring, J., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gerring_2006 += 1         \n",
    "    if 'Gerring, J., 2007' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gerring_2007 += 1         \n",
    "    if 'Gersick, C., 1991' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gersick += 1         \n",
    "    if 'Ghazawneh, A., Henfridsson' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ghazawneh += 1         \n",
    "    if 'Gibbert, M., Ruigrok, W., 2010' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gibbert_2010 += 1         \n",
    "    if 'Gibbert, M., Ruigrok, W., Wicki, B., 2008' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gibbert_2008 += 1         \n",
    "    if 'Gimpel, K., Schneider' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gimpel += 1         \n",
    "    if 'Gioia, D., Corley' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gioia += 1 \n",
    "    if 'Glaser, B., 1978' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        glaser_1978 += 1 \n",
    "    if 'Glaser, B., Strauss' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        glaser_1967 += 1         \n",
    "    if 'Goetz, J., LeCompte' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        goetz += 1         \n",
    "    if 'Golden, B., 1992' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        golden += 1         \n",
    "    if 'Golsorkhi, D., Rouleau' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        golsorkhi += 1         \n",
    "    if 'Gregor, S., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gregor += 1         \n",
    "    if 'Gregory, R., Beck' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gregory_2013 += 1         \n",
    "    if 'Gregory, R., Keil, M., 2014' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gregory_2014 += 1         \n",
    "    if 'Gregory, R., Keil, M., Muntermann' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        gregory_2015 += 1  \n",
    "    if 'Guillemette, M., Pare' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        guill += 1      \n",
    "    if 'Huang, J., Pan' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        huang += 1        \n",
    "    if 'Huber, G., Power' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        huber += 1      \n",
    "    if 'Huberman, A., Miles' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        huberman += 1        \n",
    "    if 'Jarzabkowski, P., 2005' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        jarz_2005 += 1      \n",
    "    if 'Jarzabkowski, P., 2010' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        jarz_2010 += 1\n",
    "    if 'Johns, G., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        johns += 1      \n",
    "    if 'Kaplan, S., 2008' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        kaplan += 1        \n",
    "    if 'Katz, E., Haas' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        katz += 1      \n",
    "    if 'Keil, T., 2002' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        keil += 1        \n",
    "    if 'Kelly, G., 1955' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        kelly += 1      \n",
    "    if 'Kirsch, L., 2004' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        kirsch += 1        \n",
    "    if 'Kirsh, D., Maglio' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        kirsh += 1      \n",
    "    if 'Klein, H., Myers' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        klein += 1        \n",
    "    if 'Krippendorff, K., 2004' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        krippe += 1      \n",
    "    if 'Kuzel, A., 1992' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        kuzel += 1        \n",
    "    if 'Langley, A., 1999' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        langley += 1      \n",
    "    if 'Lee, A., 1989' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        lee_1989 += 1        \n",
    "    if 'Lee, A., Baskerville' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        lee_2003 += 1      \n",
    "    if 'Lee, J., Berente' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        lee_2012 += 1        \n",
    "    if 'Leonardi, P., 2013' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        leonardi += 1      \n",
    "    if 'Lincoln, Y., Guba' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        lincoln += 1        \n",
    "    if 'Locke, K., Golden' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        locke += 1      \n",
    "    if 'Mantere, S., Ketokivi' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mantere += 1        \n",
    "    if 'Markus, M., 1989' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        markus += 1      \n",
    "    if 'Mays, N., Pope' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mays += 1         \n",
    "    if 'Miles, M., Huberman' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        miles_1994 += 1      \n",
    "    if 'Miles, R., Snow' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        miles_1978 += 1         \n",
    "    if 'Miller, C., Cardinal' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        miller += 1      \n",
    "    if 'Mimno, D., McCallum' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mimno += 1         \n",
    "    if 'Mingers, J., 2014' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mingers += 1      \n",
    "    if 'Mingers, J., Willcocks, L., 2014' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mingers_will_2014 += 1         \n",
    "    if 'Mingers, J., Willcocks, L., 2017' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        mingers_will_2017 += 1      \n",
    "    if 'Montealegre, R., 2002' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        monte += 1         \n",
    "    if 'Myers, M., 1997' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        myers_1997 += 1      \n",
    "    if 'Myers, M., 2009' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        myers_2009 += 1         \n",
    "    if 'Myers, M., Newman' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        myers_2007 += 1  \n",
    "    if 'Ngwenyama, O., Klein' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ngwenyama += 1         \n",
    "    if 'Niiniluoto, I., 1999' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        nii += 1      \n",
    "    if 'Pan, S., Tan' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pan += 1 \n",
    "    if 'Pare, G., 2004' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pare += 1         \n",
    "    if 'Patton, M., 1990' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        patton_1990 += 1      \n",
    "    if 'Patton, M., 2002' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        patton_2002 += 1\n",
    "    if 'Pentland, B., 1999' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pentland += 1         \n",
    "    if 'Pettigrew, A., 1990' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pettigrew += 1      \n",
    "    if 'Pickering, A., 1993' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pick += 1\n",
    "    if 'Poole, M., Lambert' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        poole += 1         \n",
    "    if 'Pratt, M., 2008' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        pratt += 1      \n",
    "    if 'Reich, B., Benbasat' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        reich += 1\n",
    "    if 'Reynolds, T., Gutman' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        reynolds += 1         \n",
    "    if 'Rubin, H., Rubin' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        rubin += 1      \n",
    "    if 'Sabherwal, R., Chan, Y., 2001' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        sab_2001 += 1\n",
    "    if 'Sabherwal, R., Robey, D., 1995' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        sab_1995 += 1         \n",
    "    if 'Sarker, S., Sarker' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        sarker += 1      \n",
    "    if 'Schultze, U., Avital' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        schultze += 1\n",
    "    if 'Seidel, S., Recker' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        seidel += 1         \n",
    "    if 'Siggelkow, N., 2007' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        siggelkow += 1      \n",
    "    if 'Spradley, J., 1979' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        spradley += 1\n",
    "    if 'Strauss, A., Corbin' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        strauss += 1      \n",
    "    if 'Street, C., Ward' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        street += 1\n",
    "    if 'Strong, D., Volkoff' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        strong += 1         \n",
    "    if 'Tan, B., Pan' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        tan += 1      \n",
    "    if 'Tsang, E., 2014' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        tsang += 1\n",
    "    if 'Urquhart, C., 2013' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ur_2013 += 1      \n",
    "    if 'Urquhart, C., Lehmann' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ur_2010 += 1\n",
    "    if 'Uys, J., Du Preez' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        uys += 1         \n",
    "    if 'Van de Ven, A., 1992' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ven_1992 += 1      \n",
    "    if 'Van de Ven, A., 2007' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ven_2007 += 1\n",
    "    if 'Van de Ven, A., Poole' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        ven_1995 += 1      \n",
    "    if 'Venkatesh, V., Brown' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        venka += 1\n",
    "    if 'Voss, C., Tsikriktsis' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        voss += 1         \n",
    "    if 'Walsh, I., Holton' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        walsh += 1      \n",
    "    if 'Walsham, G., 2006' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        walsham += 1\n",
    "    if 'Weick, K., 1995' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        weick += 1      \n",
    "    if 'Yin, R., 1984' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_1984 += 1\n",
    "    if 'Yin, R., 1994. App' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_1994a += 1 \n",
    "    if 'Yin, R., 1994. Case' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_1994b += 1  \n",
    "    if 'Yin, R., 2002. Case' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_2002 += 1      \n",
    "    if 'Yin, R., 2003. Case' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_2003 += 1\n",
    "    if 'Yin, R., 2009. Case' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_2009 += 1         \n",
    "    if 'Yin, R., 2014. Case' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_2014 += 1      \n",
    "    if 'Yin, R., 2015. Qual' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yin_2015 += 1\n",
    "    if 'Yoo, Y., Henfridsson' in df['Methodological literature cited DETAIL'].iloc[i]:\n",
    "        yoo += 1\n",
    "\n",
    "print('Allison: ', allison)\n",
    "print('Alvesson: ', alvesson)\n",
    "print('Bala, H., Venkatesh: ', bala)\n",
    "print('Barley: ', barley)\n",
    "print('Barrett, M., Oborn: ', barrett)\n",
    "print('Bechky, B., Okhuysen: ', bechky)\n",
    "print('Benbasat, I., Goldstein, D., Mead, M., 1987: ', benbasat_1987)\n",
    "print('Benbasat, I., Goldstein, D., Mead, M., 1997: ', benbasat_1997)\n",
    "print('Biernacki, P., Waldorf: ', biernacki)\n",
    "print('Birks, D., Fern: ', birks)\n",
    "print('Blei, D., 2012: ', blei)\n",
    "print('Bowen, G., 2006: ', bowen_2006)\n",
    "print('Bowen, G., 2008: ', bowen_2008)\n",
    "print('Boyatzis, R., 1998: ', boyatzis)\n",
    "print('Bryant, A., Charmaz: ', bryant)\n",
    "print('urton-Jones, A., McLean: ', burton)\n",
    "print('Chan, Y., Reich: ', chan)\n",
    "print('Charmaz, K., 2006: ', charmaz_2006)\n",
    "print('Charmaz, K., 2014: ', charmaz_2014)\n",
    "print('Corbin, J., Strauss, A., 1990: ', corbin_1990)\n",
    "print('Corbin, J., Strauss, A., 2008: ', corbin_2008)\n",
    "print('Creswell, J., Clark: ', creswell)\n",
    "print('Darke, P., Shanks: ', darke)\n",
    "print('Denzin, N., 1997: ', denzin_1997)\n",
    "print('Denzin, N., Lincoln: ', denzin_2000)\n",
    "print('Dube, L., Pare: ', dube)\n",
    "print('Easterby-Smith, M., Thorpe: ', easterby)\n",
    "print('Edmondson, A., McManus: ', edmonson)\n",
    "print('Eisenhardt, K., 1989: ', eisen_1989)\n",
    "print('Eisenhardt, K., 2000: ', eisen_2000)\n",
    "print('Eisenhardt, K., Graebner: ', eisen_2007)\n",
    "print('Elbanna, A., 2010: ', elbanna)\n",
    "print('Elsbach, K., Sutton: ', elsbach)\n",
    "print('Gerring, J., 2006: ', gerring_2006)\n",
    "print('Gerring, J., 2007: ', gerring_2007)\n",
    "print('Gersick, C., 1991: ', gersick)\n",
    "print('Ghazawneh, A., Henfridsson: ', ghazawneh)\n",
    "print('Gibbert, M., Ruigrok, W., 2010: ', gibbert_2010)\n",
    "print('Gibbert, M., Ruigrok, W., Wicki, B., 2008: ', gibbert_2008)\n",
    "print('Gimpel, K., Schneider: ', gimpel)\n",
    "print('Gioia, D., Corley: ', gioia)\n",
    "print('Glaser, B., 1978: ', glaser_1978)\n",
    "print('Glaser, B., Strauss: ', glaser_1967)\n",
    "print('Goetz, J., LeCompte: ', goetz)\n",
    "print('Golden, B., 1992: ', golden)\n",
    "print('Golsorkhi, D., Rouleau: ', golsorkhi)\n",
    "print('Gregor, S., 2006: ', gregor)\n",
    "print('Gregory, R., Beck: ', gregory_2013)\n",
    "print('Gregory, R., Keil, M., 2014: ', gregory_2014)\n",
    "print('Gregory, R., Keil, M., Muntermann: ', gregory_2015)\n",
    "print('Guillemette, M., Pare: ', guill)\n",
    "print('Huang, J., Pan: ', huang)\n",
    "print('Huber, G., Power: ', huber)\n",
    "print('Huberman, A., Miles: ', huberman)\n",
    "print('Jarzabkowski, P., 2005: ', jarz_2005)\n",
    "print('Jarzabkowski, P., 2010: ', jarz_2010)\n",
    "print('Johns, G., 2006: ', johns)\n",
    "print('Kaplan, S., 2008: ', kaplan)\n",
    "print('Katz, E., Haas: ', katz)\n",
    "print('Keil, T., 2002: ', keil)\n",
    "print('Kelly, G., 1955: ', kelly)\n",
    "print('Kirsch, L., 2004: ', kirsch)\n",
    "print('Kirsh, D., Maglio: ', kirsh)\n",
    "print('Klein, H., Myers: ', klein)\n",
    "print('Krippendorff, K., 2004: ', krippe)\n",
    "print('Kuzel, A., 1992: ', kuzel)\n",
    "print('Langley, A., 1999: ', langley)\n",
    "print('Lee, A., 1989: ', lee_1989)\n",
    "print('Lee, A., Baskerville: ', lee_2003)\n",
    "print('Lee, J., Berente: ', lee_2012)\n",
    "print('Leonardi, P., 2013: ', leonardi)\n",
    "print('Lincoln, Y., Guba: ', lincoln)\n",
    "print('Locke, K., Golden: ', locke)\n",
    "print('Mantere, S., Ketokivi: ', mantere)\n",
    "print('Markus, M., 1989: ', markus)\n",
    "print('Mays, N., Pope: ', mays)\n",
    "print('Miles, M., Huberman: ', miles_1994)\n",
    "print('Miles, R., Snow: ', miles_1978)\n",
    "print('Miller, C., Cardinal: ', miller)\n",
    "print('Mimno, D., McCallum: ', mimno)\n",
    "print('Mingers, J., 2014: ', mingers)\n",
    "print('Mingers, J., Willcocks, L., 2014: ', mingers_will_2014)\n",
    "print('Mingers, J., Willcocks, L., 2017: ', mingers_will_2017)\n",
    "print('Montealegre, R., 2002: ', monte)\n",
    "print('Myers, M., 1997: ', myers_1997)\n",
    "print('Myers, M., 2009: ', myers_2009)\n",
    "print('Myers, M., Newman: ', myers_2007)\n",
    "print('Ngwenyama, O., Klein: ', ngwenyama)\n",
    "print('Niiniluoto, I., 1999: ', nii)\n",
    "print('Pan, S., Tan: ', pan)\n",
    "print('Pare, G., 2004: ', pare)\n",
    "print('Patton, M., 1990: ', patton_1990)\n",
    "print('Patton, M., 2002: ', patton_2002)\n",
    "print('Pentland, B., 1999: ', pentland)\n",
    "print('Pettigrew, A., 1990: ', pettigrew)\n",
    "print('Pickering, A., 1993: ', pick)\n",
    "print('Poole, M., Lambert: ', poole)\n",
    "print('Pratt, M., 2008: ', pratt)\n",
    "print('Reich, B., Benbasat: ', reich)\n",
    "print('Reynolds, T., Gutman: ', reynolds)\n",
    "print('Rubin, H., Rubin: ', rubin)\n",
    "print('Sabherwal, R., Chan, Y., 2001: ', sab_2001)\n",
    "print('Sabherwal, R., Robey, D., 1995: ', sab_1995)\n",
    "print('Sarker, S., Sarker: ', sarker)\n",
    "print('Schultze, U., Avital: ', schultze)\n",
    "print('Seidel, S., Recker: ', seidel)\n",
    "print('Siggelkow, N., 2007: ', siggelkow)\n",
    "print('Spradley, J., 1979: ', spradley)\n",
    "print('Strauss, A., Corbin: ', strauss)\n",
    "print('Street, C., Ward: ', street)\n",
    "print('Strong, D., Volkoff: ', strong)\n",
    "print('Tan, B., Pan: ', tan)\n",
    "print('Tsang, E., 2014: ', tsang)\n",
    "print('Urquhart, C., 2013: ', ur_2013)\n",
    "print('Urquhart, C., Lehmann: ', ur_2010)\n",
    "print('Uys, J., Du Preez: ', uys)\n",
    "print('Van de Ven, A., 1992: ', ven_1992)\n",
    "print('Van de Ven, A., 2007: ', ven_2007)\n",
    "print('Van de Ven, A., Poole: ', ven_1995)\n",
    "print('Venkatesh, V., Brown: ', venka)\n",
    "print('Voss, C., Tsikriktsis: ', voss)\n",
    "print('Walsh, I., Holton: ', walsh)\n",
    "print('Walsham, G., 2006: ', walsham)\n",
    "print('Weick, K., 1995: ', weick)\n",
    "print('Yin, R., 1984: ', yin_1984)\n",
    "print('Yin, R., 1994. App: ', yin_1994a)\n",
    "print('Yin, R., 1994. Case: ', yin_1994b)\n",
    "print('Yin, R., 2002. Case: ', yin_2002)\n",
    "print('Yin, R., 2003. Case: ', yin_2003)\n",
    "print('Yin, R., 2009. Case: ', yin_2009)\n",
    "print('Yin, R., 2014. Case: ', yin_2014)\n",
    "print('Yin, R., 2015. Qual: ', yin_2015)\n",
    "print('Yoo, Y., Henfridsson: ', yoo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8dae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d30b48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other case studies cited:  23  =>  0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "#Other case studies cited\n",
    "\n",
    "other_cs_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Other case studies cited'].iloc[i] == 'yes':\n",
    "        other_cs_all += 1\n",
    "\n",
    "print('Other case studies cited: ', other_cs_all, ' => ', other_cs_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5e81544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online-Appendix:  2  =>  0.05714285714285714\n"
     ]
    }
   ],
   "source": [
    "#Online-Appendix\n",
    "\n",
    "online_appendix_all = 0\n",
    "\n",
    "for i in range(0, all_len):\n",
    "    if df['Online-Appendix'].iloc[i] == 'yes':\n",
    "        online_appendix_all += 1\n",
    "\n",
    "print('Online-Appendix: ', online_appendix_all, ' => ', online_appendix_all/all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7149084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
