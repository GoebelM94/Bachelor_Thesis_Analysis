{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fffbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8833f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Excel file with data\n",
    "xlx = '../data/Coding_JSIS_MISQ_V5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3d2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f859123d",
   "metadata": {},
   "source": [
    "# descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11ad71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Excel file to dataframe\n",
    "\n",
    "df = pd.read_excel(xlx, header=0)\n",
    "\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc66fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number descriptive CS:  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Jahr</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Autor/en</th>\n",
       "      <th>Use of CSR stated</th>\n",
       "      <th>Use of CSR stated DETAIL</th>\n",
       "      <th>CSR used in keywords</th>\n",
       "      <th>CSR used in keywords DETAIL</th>\n",
       "      <th>...</th>\n",
       "      <th>Comparison with similar literature (only exploratory) DETAIL</th>\n",
       "      <th>Key case study characteristics summarized</th>\n",
       "      <th>Key case study characteristics summarized  DETAIL</th>\n",
       "      <th>Methodological literature cited</th>\n",
       "      <th>Methodological literature cited DETAIL</th>\n",
       "      <th>Other case studies cited</th>\n",
       "      <th>Other case studies cited DETAIL</th>\n",
       "      <th>Online-Appendix</th>\n",
       "      <th>Online-Appendix DETAIL</th>\n",
       "      <th>Classification in terms of methodological rigor (descending: ++, +, o, -)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>Managing potentially disruptive innovations in...</td>\n",
       "      <td>2015</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Kaltenecker, Thomas Hess, Stefan Huesig</td>\n",
       "      <td>yes</td>\n",
       "      <td>Bearing the current\\nstate of research in mind...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Yin, R., 2009. Case Study Research: Design and...</td>\n",
       "      <td>yes</td>\n",
       "      <td>In the context of managing dramatic changes du...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JSIS</td>\n",
       "      <td>The influence of entrepreneurial action on str...</td>\n",
       "      <td>2018</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Chris Street, Brent Gallupe, Jeff Baker</td>\n",
       "      <td>yes</td>\n",
       "      <td>In the methodology section, we describe our po...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>yes</td>\n",
       "      <td>Dube, L., Pare, G., 2003. Rigor in information...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Third, retrospective case studies, which have ...</td>\n",
       "      <td>no</td>\n",
       "      <td>-</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Journal                                              Titel  Jahr  Volume  \\\n",
       "4     JSIS  Managing potentially disruptive innovations in...  2015      24   \n",
       "10    JSIS  The influence of entrepreneurial action on str...  2018      27   \n",
       "\n",
       "    Issue                                         Autor/en Use of CSR stated  \\\n",
       "4       4  Natalie Kaltenecker, Thomas Hess, Stefan Huesig               yes   \n",
       "10      1          Chris Street, Brent Gallupe, Jeff Baker               yes   \n",
       "\n",
       "                             Use of CSR stated DETAIL CSR used in keywords  \\\n",
       "4   Bearing the current\\nstate of research in mind...                   no   \n",
       "10  In the methodology section, we describe our po...                   no   \n",
       "\n",
       "   CSR used in keywords DETAIL  ...  \\\n",
       "4                            -  ...   \n",
       "10                           -  ...   \n",
       "\n",
       "   Comparison with similar literature (only exploratory) DETAIL  \\\n",
       "4                                                 NaN             \n",
       "10                                                NaN             \n",
       "\n",
       "   Key case study characteristics summarized   \\\n",
       "4                                          no   \n",
       "10                                         no   \n",
       "\n",
       "   Key case study characteristics summarized  DETAIL  \\\n",
       "4                                                  -   \n",
       "10                                                 -   \n",
       "\n",
       "   Methodological literature cited  \\\n",
       "4                              yes   \n",
       "10                             yes   \n",
       "\n",
       "               Methodological literature cited DETAIL  \\\n",
       "4   Yin, R., 2009. Case Study Research: Design and...   \n",
       "10  Dube, L., Pare, G., 2003. Rigor in information...   \n",
       "\n",
       "   Other case studies cited  \\\n",
       "4                       yes   \n",
       "10                      yes   \n",
       "\n",
       "                      Other case studies cited DETAIL Online-Appendix  \\\n",
       "4   In the context of managing dramatic changes du...              no   \n",
       "10  Third, retrospective case studies, which have ...              no   \n",
       "\n",
       "   Online-Appendix DETAIL  \\\n",
       "4                       -   \n",
       "10                      -   \n",
       "\n",
       "   Classification in terms of methodological rigor (descending: ++, +, o, -)  \n",
       "4                                                   +                         \n",
       "10                                                  +                         \n",
       "\n",
       "[2 rows x 187 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe for descriptive research purpose\n",
    "\n",
    "df = df.loc[df['Research purpose'] == 'descriptive']\n",
    "purpose_len = len(df)\n",
    "print('Number descriptive CS: ', purpose_len)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2019b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number single cases:  0\n",
      "Number multiple cases:  2\n"
     ]
    }
   ],
   "source": [
    "# dataframes for single and multiple CS\n",
    "\n",
    "# 1. single CS\n",
    "df_single = df.loc[df['Number of cases'] == 1]\n",
    "single_len = len(df_single)\n",
    "print('Number single cases: ', single_len)\n",
    "#df_single.head()\n",
    "\n",
    "#2. multiple CS\n",
    "df_multiple = df.loc[df['Number of cases'] > 1]\n",
    "multiple_len = len(df_multiple)\n",
    "print('Number multiple cases: ', multiple_len)\n",
    "#df_multiple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9e4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number interview cases:  2\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including interviews\n",
    "\n",
    "df_interv = df.loc[df['Interviews '] == 'yes']\n",
    "interv_len = len(df_interv)\n",
    "print('Number interview cases: ', interv_len)\n",
    "#df_interv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333fe09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Questionnaires cases:  0\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including questionnaires\n",
    "\n",
    "df_quest = df.loc[df['Questionnaires'] == 'yes']\n",
    "quest_len = len(df_quest)\n",
    "print('Number Questionnaires cases: ', quest_len)\n",
    "#df_quest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a288587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number coding cases:  2\n"
     ]
    }
   ],
   "source": [
    "# dataframe for CS including coding\n",
    "\n",
    "df_code = df.loc[df['Coding of raw data'] == 'yes']\n",
    "code_len = len(df_code)\n",
    "print('Number coding cases: ', code_len)\n",
    "#df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc743d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f11af1",
   "metadata": {},
   "source": [
    "_**Research Design**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b63df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting CSR:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting CSR\n",
    "\n",
    "rationale_csr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for conducting CSR'].iloc[i] == 'yes':\n",
    "        rationale_csr_all += 1\n",
    "\n",
    "print('Rationale for conducting CSR: ', rationale_csr_all, ' => ', rationale_csr_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a42a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research question all:  2  =>  1.0\n",
      "goal with interrogative all:  0  =>  0.0\n",
      "goal without interrogative all:  0  =>  0.0\n",
      "\n",
      "Research question or goal with interrogative all:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Clear research questions \n",
    "\n",
    "question_all = 0\n",
    "w_interr_all = 0\n",
    "wo_interr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Clear research questions '].iloc[i] == 'yes':\n",
    "        question_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal with interrogative':\n",
    "        w_interr_all += 1\n",
    "    elif df['Clear research questions '].iloc[i] == 'goal without interrogative':\n",
    "        wo_interr_all += 1\n",
    "\n",
    "print('Research question all: ', question_all, ' => ', question_all/purpose_len)\n",
    "print('goal with interrogative all: ', w_interr_all, ' => ', w_interr_all/purpose_len)\n",
    "print('goal without interrogative all: ', wo_interr_all, ' => ', wo_interr_all/purpose_len)\n",
    "print('')\n",
    "print('Research question or goal with interrogative all: ', question_all+w_interr_all, ' => ',  (question_all+w_interr_all)/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c1c630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['how'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of research questions \n",
    "\n",
    "types_rq = df['Types of research questions '].unique()\n",
    "types_rq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55e8de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case acquisition strategy:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Case acquisition strategy\n",
    "\n",
    "acquisition_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case acquisition strategy'].iloc[i] == 'yes':\n",
    "        acquisition_all += 1\n",
    "\n",
    "print('Case acquisition strategy: ', acquisition_all, ' => ', acquisition_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "082a3b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cases\n",
    "\n",
    "number_cases = df['Number of cases'].unique()\n",
    "number_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0930a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for conducting a single/multiple case study:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Rationale for conducting a single/multiple case study\n",
    "\n",
    "rationale_single_multiple_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for conducting a single/multiple case study'].iloc[i] == 'yes':\n",
    "        rationale_single_multiple_all += 1\n",
    "\n",
    "print('Rationale for conducting a single/multiple case study: ', rationale_single_multiple_all, ' => ', rationale_single_multiple_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed72db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nature of single-case design\n",
    "\n",
    "criterion_all = 0\n",
    "extreme_all = 0\n",
    "intensity_all = 0\n",
    "revelatory_all = 0\n",
    "theoretical_all = 0\n",
    "typical_all = 0\n",
    "unique_all = 0\n",
    "\n",
    "if single_len > 0:\n",
    "    for i in range(0, single_len):\n",
    "        if df_single['Nature of single-case design'].iloc[i] == 'criterion':\n",
    "            criterion_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'extreme':\n",
    "            extreme_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'intensity':\n",
    "            intensity_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'revelatory':\n",
    "            revelatory_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'theoretical':\n",
    "            theoretical_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'typical':\n",
    "            typical_all += 1\n",
    "        elif df_single['Nature of single-case design'].iloc[i] == 'unique':\n",
    "            unique_all += 1    \n",
    "\n",
    "    print('criterion: ', criterion_all, ' => ', criterion_all/single_len)\n",
    "    print('extreme: ', extreme_all, ' => ', extreme_all/single_len)\n",
    "    print('intensity: ', intensity_all, ' => ', intensity_all/single_len)\n",
    "    print('revelatory: ', revelatory_all, ' => ', revelatory_all/single_len)\n",
    "    print('theoretical: ', theoretical_all, ' => ', theoretical_all/single_len)\n",
    "    print('typical: ', typical_all, ' => ', typical_all/single_len)\n",
    "    print('unique: ', unique_all, ' => ', unique_all/single_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5343de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literal:  0  =>  0.0\n",
      "theoretical:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Replication logic in multiple-case design\n",
    "\n",
    "literal_all = 0\n",
    "theoretical_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Replication logic in multiple-case design'].iloc[i] == 'literal':\n",
    "        literal_all += 1\n",
    "    elif df_multiple['Replication logic in multiple-case design'].iloc[i] == 'theoretical':\n",
    "        theoretical_all += 1\n",
    "\n",
    "print('literal: ', literal_all, ' => ', literal_all/multiple_len)\n",
    "print('theoretical: ', theoretical_all, ' => ', theoretical_all/multiple_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "922a9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s reasonably chosen:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Case/s reasonably chosen\n",
    "\n",
    "cases_reason_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case/s reasonably chosen'].iloc[i] == 'yes':\n",
    "        cases_reason_all += 1\n",
    "\n",
    "print('Case/s reasonably chosen: ', cases_reason_all, ' => ', cases_reason_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "640e4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case/s defined:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Case/s defined\n",
    "\n",
    "cases_def_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case/s defined'].iloc[i] == 'yes':\n",
    "        cases_def_all += 1\n",
    "\n",
    "print('Case/s defined: ', cases_def_all, ' => ', cases_def_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7616fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case/s\n",
    "\n",
    "cases = df['Case/s'].unique()\n",
    "#cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fba81e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit of analysis stated:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Unit of analysis stated\n",
    "\n",
    "uoa_stated_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Unit of analysis stated'].iloc[i] == 'yes':\n",
    "        uoa_stated_all += 1\n",
    "\n",
    "print('Unit of analysis stated: ', uoa_stated_all, ' => ', uoa_stated_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1af4ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit of analysis\n",
    "\n",
    "uoa = df['Unit of analysis'].unique()\n",
    "#uoa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45526542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale for choosing the unit of analysis:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Rationale for choosing the unit of analysis\n",
    "\n",
    "rationale_uoa_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale for choosing the unit of analysis'].iloc[i] == 'yes':\n",
    "        rationale_uoa_all += 1\n",
    "\n",
    "print('Rationale for choosing the unit of analysis: ', rationale_uoa_all, ' => ', rationale_uoa_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef35460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case design:  2  =>  1.0\n",
      "Case design:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Case design\n",
    "\n",
    "embedded_all = 0\n",
    "holistic_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case design'].iloc[i] == 'embedded':\n",
    "        embedded_all += 1\n",
    "    elif df['Case design'].iloc[i] == 'holistic':\n",
    "        holistic_all += 1\n",
    "\n",
    "print('Case design: ', embedded_all, ' => ', embedded_all/purpose_len)\n",
    "print('Case design: ', holistic_all, ' => ', holistic_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfa49031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale research site:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Rationale research site\n",
    "\n",
    "rationale_site_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Rationale research site'].iloc[i] == 'yes' or df['Rationale research site'].iloc[i] == 'yes, see case selection':\n",
    "        rationale_site_all += 1\n",
    "\n",
    "print('Rationale research site: ', rationale_site_all, ' => ', rationale_site_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "505226f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  1  =>  0.5\n",
      "rough:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Detail research site\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Detail research site'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Detail research site'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc46ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on-site:  2  =>  1.0\n",
      "off-site:  0  =>  0.0\n",
      "both:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Research site\n",
    "\n",
    "on_all = 0\n",
    "off_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Research site'].iloc[i] == 'on-site':\n",
    "        on_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'off-site':\n",
    "        off_all += 1\n",
    "    elif df['Research site'].iloc[i] == 'on-site, off-side':\n",
    "        both_all += 1\n",
    "\n",
    "print('on-site: ', on_all, ' => ', on_all/purpose_len)\n",
    "print('off-site: ', off_all, ' => ', off_all/purpose_len)\n",
    "print('both: ', both_all, ' => ', both_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b07e08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of a pilot case:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Use of a pilot case\n",
    "\n",
    "pilot_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Use of a pilot case'].iloc[i] == 'yes':\n",
    "        pilot_all += 1\n",
    "\n",
    "print('Use of a pilot case: ', pilot_all, ' => ', pilot_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78178137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site description:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Site description\n",
    "\n",
    "site_descr_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Site description'].iloc[i] != 'not specified':\n",
    "        site_descr_all += 1\n",
    "\n",
    "print('Site description: ', site_descr_all, ' => ', site_descr_all/purpose_len)\n",
    "\n",
    "site_descr_unique = df['Site description'].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f35814e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case period:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Case period\n",
    "\n",
    "period_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case period '].iloc[i] != 'not specified':\n",
    "        period_all += 1\n",
    "\n",
    "print('Case period: ', period_all, ' => ', period_all/purpose_len)\n",
    "\n",
    "site_descr_unique = df['Case period '].unique()\n",
    "#site_descr_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d16517a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal design:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Longitudinal design\n",
    "\n",
    "long_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Longitudinal design'].iloc[i] == 'yes':\n",
    "        long_all += 1\n",
    "\n",
    "print('Longitudinal design: ', long_all, ' => ', long_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81ed55ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent on site (for data collection):  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Time spent on site (for data collection)\n",
    "\n",
    "time_spent_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Time spent on site (for data collection)'].iloc[i] != 'not specified':\n",
    "        time_spent_all += 1\n",
    "\n",
    "print('Time spent on site (for data collection): ', time_spent_all, ' => ', time_spent_all/purpose_len)\n",
    "\n",
    "time_spent_unique = df['Time spent on site (for data collection)'].unique()\n",
    "#time_spent_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ecca50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  0  =>  0.0\n",
      "2:  0  =>  0.0\n",
      "3:  2  =>  1.0\n",
      "4:  0  =>  0.0\n",
      "5:  0  =>  0.0\n",
      "6:  0  =>  0.0\n",
      "Team-based research:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of authors  \n",
    "\n",
    "one_all = 0\n",
    "two_all = 0\n",
    "three_all = 0\n",
    "four_all = 0\n",
    "five_all = 0\n",
    "six_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of authors  '].iloc[i] == 1:\n",
    "        one_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 2:\n",
    "        two_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 3:\n",
    "        three_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 4:\n",
    "        four_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 5:\n",
    "        five_all += 1\n",
    "    elif df['Number of authors  '].iloc[i] == 6:\n",
    "        six_all += 1\n",
    "\n",
    "print('1: ', one_all, ' => ', one_all/purpose_len)\n",
    "print('2: ', two_all, ' => ', two_all/purpose_len)\n",
    "print('3: ', three_all, ' => ', three_all/purpose_len)\n",
    "print('4: ', four_all, ' => ', four_all/purpose_len)\n",
    "print('5: ', five_all, ' => ', five_all/purpose_len)\n",
    "print('6: ', six_all, ' => ', six_all/purpose_len)\n",
    "print('Team-based research: ', purpose_len-one_all, ' => ', (purpose_len-one_all)/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f73fcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Involvement of the researcher:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Involvement of the researcher\n",
    "\n",
    "involved_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Involvement of the researcher'].iloc[i] == 'involved':\n",
    "        involved_all += 1\n",
    "\n",
    "print('Involvement of the researcher: ', involved_all, ' => ', involved_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a723d1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different roles for multiple investigators:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Different roles for multiple investigators\n",
    "\n",
    "diff_roles_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Different roles for multiple investigators'].iloc[i] == 'yes':\n",
    "        diff_roles_all += 1\n",
    "\n",
    "print('Different roles for multiple investigators: ', diff_roles_all, ' => ', diff_roles_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b071f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc134e3",
   "metadata": {},
   "source": [
    "_**Data Collection**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecc39cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  2  =>  1.0\n",
      "rough:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data collection process \n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Elucidation of the data collection process '].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data collection process '].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00317398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interviews :  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Interviews \n",
    "\n",
    "interviews_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Interviews '].iloc[i] == 'yes':\n",
    "        interviews_all += 1\n",
    "\n",
    "print('Interviews : ', interviews_all, ' => ', interviews_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a563dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semi-structured:  1  =>  0.5\n",
      "structured:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Kind of interviews\n",
    "\n",
    "semi_all = 0\n",
    "struct_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Kind of interviews'].iloc[i] == 'semi-structured':\n",
    "        semi_all += 1\n",
    "    elif df_interv['Kind of interviews'].iloc[i] == 'structured':\n",
    "        struct_all += 1\n",
    "\n",
    "print('semi-structured: ', semi_all, ' => ', semi_all/interv_len)\n",
    "print('structured: ', struct_all, ' => ', struct_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "711ac7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:  0  =>  0.0\n",
      "purposeful:  1  =>  0.5\n",
      "snowball:  1  =>  0.5\n",
      "maximum variation:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Sampling strategy (interviews) (up to three)\n",
    "\n",
    "criterion_all = 0\n",
    "purposeful_all = 0\n",
    "snowball_all = 0\n",
    "variation_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if 'criterion' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        criterion_all += 1\n",
    "    if 'purposeful' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        purposeful_all += 1\n",
    "    if 'snowball' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        snowball_all += 1\n",
    "    if 'maximum variation' in df_interv['Sampling strategy (interviews) (up to three)'].iloc[i]:\n",
    "        variation_all += 1\n",
    "\n",
    "print('criterion: ', criterion_all, ' => ', criterion_all/interv_len)\n",
    "print('purposeful: ', purposeful_all, ' => ', purposeful_all/interv_len)\n",
    "print('snowball: ', snowball_all, ' => ', snowball_all/interv_len)\n",
    "print('maximum variation: ', variation_all, ' => ', variation_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "914617f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviewees:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of interviewees \n",
    "\n",
    "number_interviewees_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviewees '].iloc[i] != 'not specified':\n",
    "        number_interviewees_all += 1\n",
    "\n",
    "print('Number of interviewees: ', number_interviewees_all, ' => ', number_interviewees_all/interv_len)\n",
    "\n",
    "number_interviewees_unique = df_interv['Number of interviewees '].unique()\n",
    "#number_interviewees_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0abfd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of interviews:  0  =>  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of interviews\n",
    "\n",
    "number_interviews_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Number of interviews'].iloc[i] != 'not specified':\n",
    "        number_interviews_all += 1\n",
    "\n",
    "print('Number of interviews: ', number_interviews_all, ' => ', number_interviews_all/interv_len)\n",
    "\n",
    "number_interviews_unique = df_interv['Number of interviews'].unique()\n",
    "number_interviews_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c82fc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  0  =>  0.0\n",
      "concrete examples:  0  =>  0.0\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  1  =>  0.5\n",
      "on request:  0  =>  0.0\n",
      "not specified:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Use of an interview guide\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_interv['Use of an interview guide'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b23cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-test of interview guide:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Pre-test of interview guide\n",
    "\n",
    "interv_guide_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Pre-test of interview guide'].iloc[i] == 'yes':\n",
    "        interv_guide_all += 1\n",
    "\n",
    "print('Pre-test of interview guide: ', interv_guide_all, ' => ', interv_guide_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca46a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview transcription:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Interview transcription\n",
    "\n",
    "interv_transcr_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview transcription'].iloc[i] == 'yes':\n",
    "        interv_transcr_all += 1\n",
    "\n",
    "print('Interview transcription: ', interv_transcr_all, ' => ', interv_transcr_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b49ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview review:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Interview review\n",
    "\n",
    "interv_review_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Interview review'].iloc[i] == 'yes':\n",
    "        interv_review_all += 1\n",
    "\n",
    "print('Interview review: ', interv_review_all, ' => ', interv_review_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cf7cc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow up interviews:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Follow up interviews\n",
    "\n",
    "interv_followup_all = 0\n",
    "\n",
    "for i in range(0, interv_len):\n",
    "    if df_interv['Follow up interviews'].iloc[i] == 'yes':\n",
    "        interv_followup_all += 1\n",
    "\n",
    "print('Follow up interviews: ', interv_followup_all, ' => ', interv_followup_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f57e7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Observation \n",
    "\n",
    "obers_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Observation '].iloc[i] == 'yes':\n",
    "        obers_all += 1\n",
    "\n",
    "print('Observation: ', obers_all, ' => ', obers_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57d54da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentation:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Documentation \n",
    "\n",
    "doc_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Documentation '].iloc[i] == 'yes':\n",
    "        doc_all += 1\n",
    "\n",
    "print('Documentation: ', doc_all, ' => ', doc_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "524c2285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questionnaires:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires\n",
    "\n",
    "quest_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Questionnaires'].iloc[i] == 'yes':\n",
    "        quest_all += 1\n",
    "\n",
    "print('Questionnaires: ', quest_all, ' => ', quest_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daa3d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  0  =>  0.0\n",
      "concrete examples:  0  =>  0.0\n",
      "broad overview:  0  =>  0.0\n",
      "only mentioned:  0  =>  0.0\n",
      "on request:  0  =>  0.0\n",
      "not specified:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Questionnaires provided\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "concr_examples_all = 0\n",
    "broad_overv_all = 0\n",
    "only_ment_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, quest_len):\n",
    "    if df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, concrete examples':\n",
    "        concr_examples_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, broad overview':\n",
    "        broad_overv_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, only mentioned':\n",
    "        only_ment_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_quest['Questionnaires provided'].iloc[i] == 'not specified':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/interv_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/interv_len)\n",
    "print('concrete examples: ', concr_examples_all, ' => ', concr_examples_all/interv_len)\n",
    "print('broad overview: ', broad_overv_all, ' => ', broad_overv_all/interv_len)\n",
    "print('only mentioned: ', only_ment_all, ' => ', only_ment_all/interv_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/interv_len)\n",
    "print('not specified: ', not_spec_all, ' => ', not_spec_all/interv_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e853d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple data collection methods:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# multiple data collection methods\n",
    "\n",
    "multiple_methods_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Observation '].iloc[i] == 'yes') or (df['Interviews '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes') or (df['Observation '].iloc[i] == 'yes' and df['Documentation '].iloc[i] == 'yes'):\n",
    "        multiple_methods_all += 1\n",
    "\n",
    "print('multiple data collection methods: ', multiple_methods_all, ' => ', multiple_methods_all/purpose_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43bbcfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantitative:  0  =>  0.0\n",
      "qualitative:  2  =>  1.0\n",
      "both:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Kind of data collected\n",
    "\n",
    "quantitative_all = 0\n",
    "qualitative_all = 0\n",
    "both_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Kind of data collected'].iloc[i] == 'quantitative':\n",
    "        quantitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'qualitative':\n",
    "        qualitative_all += 1\n",
    "    elif df['Kind of data collected'].iloc[i] == 'both':\n",
    "        both_all += 1\n",
    "\n",
    "print('quantitative: ', quantitative_all, ' => ', quantitative_all/purpose_len)\n",
    "print('qualitative: ', qualitative_all, ' => ', qualitative_all/purpose_len)\n",
    "print('both: ', both_all, ' => ', both_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fbb295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data triangulation:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Data triangulation \n",
    "\n",
    "data_tri_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data triangulation '].iloc[i] == 'yes':\n",
    "        data_tri_all += 1\n",
    "\n",
    "print('Data triangulation: ', data_tri_all, ' => ', data_tri_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03439d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data collection:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data collection\n",
    "\n",
    "researcher_tri_data_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Researcher triangulation during data collection'].iloc[i] == 'yes':\n",
    "        researcher_tri_data_all += 1\n",
    "\n",
    "print('Researcher triangulation during data collection: ', researcher_tri_data_all, ' => ', researcher_tri_data_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "306c4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data collection:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of researchers conducting data collection\n",
    "\n",
    "researchers_data_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of researchers conducting data collection'].iloc[i] != 'not specified':\n",
    "        researchers_data_all += 1\n",
    "\n",
    "print('Number of researchers conducting data collection: ', researchers_data_all, ' => ', researchers_data_all/purpose_len)\n",
    "\n",
    "researchers_data_unique = df['Number of researchers conducting data collection'].unique()\n",
    "#researchers_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4859d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study protocol:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Case study protocol\n",
    "\n",
    "protocol_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case study protocol'].iloc[i] == 'yes':\n",
    "        protocol_all += 1\n",
    "\n",
    "print('Case study protocol: ', protocol_all, ' => ', protocol_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6baa78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study database:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Case study database \n",
    "\n",
    "database_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Case study database '].iloc[i] == 'yes':\n",
    "        database_all += 1\n",
    "\n",
    "print('Case study database: ', database_all, ' => ', database_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a387e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap of data collection and analysis:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Overlap of data collection and analysis\n",
    "\n",
    "overlap_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Overlap of data collection and analysis'].iloc[i] == 'yes':\n",
    "        overlap_all += 1\n",
    "\n",
    "print('Overlap of data collection and analysis: ', overlap_all, ' => ', overlap_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942570b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a093f90",
   "metadata": {},
   "source": [
    "_**Analysis**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f50a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  2  =>  1.0\n",
      "rough:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Elucidation of the data analysis process\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Elucidation of the data analysis process'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Elucidation of the data analysis process'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3dd4f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field notes:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Field notes\n",
    "\n",
    "notes_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Field notes'].iloc[i] == 'yes':\n",
    "        notes_all += 1\n",
    "\n",
    "print('Field notes: ', notes_all, ' => ', notes_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af627c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coding of raw data:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Coding of raw data\n",
    "\n",
    "code_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Coding of raw data'].iloc[i] == 'yes':\n",
    "        code_all += 1\n",
    "\n",
    "print('Coding of raw data: ', code_all, ' => ', code_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5479f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete in text:  0  =>  0.0\n",
      "complete in appendix:  0  =>  0.0\n",
      "partially:  2  =>  1.0\n",
      "on request:  0  =>  0.0\n",
      "no:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Coding scheme available\n",
    "\n",
    "compl_text_all = 0\n",
    "compl_appendix_all = 0\n",
    "partially_all = 0\n",
    "on_request_all = 0\n",
    "not_spec_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding scheme available'].iloc[i] == 'yes, complete (in text)':\n",
    "        compl_text_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, complete (in appendix)':\n",
    "        compl_appendix_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, partially':\n",
    "        partially_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'yes, on request':\n",
    "        on_request_all += 1\n",
    "    elif df_code['Coding scheme available'].iloc[i] == 'no':\n",
    "        not_spec_all += 1\n",
    "\n",
    "print('complete in text: ', compl_text_all, ' => ', compl_text_all/code_len)\n",
    "print('complete in appendix: ', compl_appendix_all, ' => ', compl_appendix_all/code_len)\n",
    "print('partially: ', partially_all, ' => ', partially_all/code_len)\n",
    "print('on request: ', on_request_all, ' => ', on_request_all/code_len)\n",
    "print('no: ', not_spec_all, ' => ', not_spec_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "943995ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of coding scheme:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Validation of coding scheme\n",
    "\n",
    "validation_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Validation of coding scheme'].iloc[i] == 'yes':\n",
    "        validation_all += 1\n",
    "\n",
    "print('Validation of coding scheme: ', validation_all, ' => ', validation_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e1dcbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example codes available:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Example codes available\n",
    "\n",
    "example_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Example codes available'].iloc[i] == 'yes':\n",
    "        example_all += 1\n",
    "\n",
    "print('Example codes available: ', example_all, ' => ', example_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6b98d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researcher triangulation during data analysis:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Researcher triangulation during data analysis\n",
    "\n",
    "researcher_tri_analysis_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Researcher triangulation during data analysis'].iloc[i] == 'yes':\n",
    "        researcher_tri_analysis_all += 1\n",
    "\n",
    "print('Researcher triangulation during data analysis: ', researcher_tri_analysis_all, ' => ', researcher_tri_analysis_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52a38837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of researchers conducting data analysis:  1  =>  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['not specified', 3], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of researchers conducting data analysis\n",
    "\n",
    "researchers_analysis_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Number of researchers conducting data analysis'].iloc[i] != 'not specified':\n",
    "        researchers_analysis_all += 1\n",
    "\n",
    "print('Number of researchers conducting data analysis: ', researchers_analysis_all, ' => ', researchers_analysis_all/purpose_len)\n",
    "\n",
    "researchers_analysis_unique = df['Number of researchers conducting data analysis'].unique()\n",
    "researchers_analysis_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6a69c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-rater reliability test :  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Inter-rater reliability test \n",
    "\n",
    "inter_rater_all = 0\n",
    "\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Inter-rater reliability test '].iloc[i] == 'yes':\n",
    "        inter_rater_all += 1\n",
    "\n",
    "print('Inter-rater reliability test : ', inter_rater_all, ' => ', inter_rater_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6111b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-rater agreement ratio\n",
    "\n",
    "inter_ratio_unique = df['Inter-rater agreement ratio'].unique()\n",
    "#inter_ratio_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1b5c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATLAS-ti:  1  =>  0.5\n",
      "Nvivo:  0  =>  0.0\n",
      "both:  1  =>  0.5\n"
     ]
    }
   ],
   "source": [
    "# Coding software\n",
    "\n",
    "atlas_all = 0\n",
    "nvivo_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, code_len):\n",
    "    if df_code['Coding software'].iloc[i] == 'ATLAS-ti':\n",
    "        atlas_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'Nvivo':\n",
    "        nvivo_all += 1\n",
    "    elif df_code['Coding software'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('ATLAS-ti: ', atlas_all, ' => ', atlas_all/code_len)\n",
    "print('Nvivo: ', nvivo_all, ' => ', nvivo_all/code_len)\n",
    "print('both: ', no_all, ' => ', no_all/code_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34c8bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explicitly:  0  =>  0.0\n",
      "implicitly:  0  =>  0.0\n",
      "no:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Data displays (technique)\n",
    "\n",
    "expl_all = 0\n",
    "impl_all = 0\n",
    "no_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data displays (technique)'].iloc[i] == 'yes, explicitly':\n",
    "        expl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'yes, implicitly':\n",
    "        impl_all += 1\n",
    "    elif df['Data displays (technique)'].iloc[i] == 'not specified':\n",
    "        no_all += 1\n",
    "\n",
    "print('explicitly: ', expl_all, ' => ', expl_all/purpose_len)\n",
    "print('implicitly: ', impl_all, ' => ', impl_all/purpose_len)\n",
    "print('no: ', no_all, ' => ', no_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bd54b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data displays:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Data displays\n",
    "\n",
    "displays_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Data displays'].iloc[i] == 'yes':\n",
    "        displays_all += 1\n",
    "\n",
    "print('Data displays: ', displays_all, ' => ', displays_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9eb2abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexible and opportunistic process:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Flexible and opportunistic process\n",
    "\n",
    "flexible_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Flexible and opportunistic process'].iloc[i] == 'yes':\n",
    "        flexible_all += 1\n",
    "\n",
    "print('Flexible and opportunistic process: ', flexible_all, ' => ', flexible_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eef63c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical chain of evidence:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Logical chain of evidence\n",
    "\n",
    "evidence_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Logical chain of evidence'].iloc[i] == 'yes':\n",
    "        evidence_all += 1\n",
    "\n",
    "print('Logical chain of evidence: ', evidence_all, ' => ', evidence_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7c69f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical testing (only explanatory):  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Empirical testing (only explanatory)\n",
    "\n",
    "empir_test_all = 0\n",
    "\n",
    "if purpose_len > 0:\n",
    "    for i in range(0, purpose_len):\n",
    "        if df['Empirical testing (only explanatory)'].iloc[i] == 'yes':\n",
    "            empir_test_all += 1\n",
    "\n",
    "    print('Empirical testing (only explanatory): ', empir_test_all, ' => ', empir_test_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d5518e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for cross-case patterns (only multiple CS):  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Search for cross-case patterns (only multiple CS)\n",
    "\n",
    "cross_all = 0\n",
    "\n",
    "for i in range(0, multiple_len):\n",
    "    if df_multiple['Search for cross-case patterns (only multiple CS)'].iloc[i] == 'yes':\n",
    "        cross_all += 1\n",
    "\n",
    "print('Search for cross-case patterns (only multiple CS): ', cross_all, ' => ', cross_all/multiple_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "491822ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in detail:  2  =>  1.0\n",
      "rough:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Description of the observed world\n",
    "\n",
    "detail_all = 0\n",
    "rough_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Description of the observed world'].iloc[i] == 'in detail':\n",
    "        detail_all += 1\n",
    "    elif df['Description of the observed world'].iloc[i] == 'rough':\n",
    "        rough_all += 1\n",
    "\n",
    "print('in detail: ', detail_all, ' => ', detail_all/purpose_len)\n",
    "print('rough: ', rough_all, ' => ', rough_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aeb80787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excerpts used:  1  =>  0.5\n",
      "quotes:  1  =>  0.5\n",
      "figures:  0  =>  0.0\n",
      "screenshots:  0  =>  0.0\n",
      "blog:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Excerpts of raw data in case report\n",
    "\n",
    "quotes_all = 0\n",
    "figures_all = 0\n",
    "screenshots_all = 0\n",
    "blog_all = 0\n",
    "excerpts_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Excerpts of raw data in case report'].iloc[i] != 'no':\n",
    "        excerpts_all += 1\n",
    "\n",
    "print('excerpts used: ', excerpts_all, ' => ', excerpts_all/purpose_len)\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if 'quotes' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        quotes_all += 1\n",
    "    if 'figures' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        figures_all += 1\n",
    "    if 'screenshots' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        screenshots_all += 1\n",
    "    if 'blog' in df['Excerpts of raw data in case report'].iloc[i]:\n",
    "        blog_all += 1\n",
    "\n",
    "print('quotes: ', quotes_all, ' => ', quotes_all/purpose_len)\n",
    "print('figures: ', figures_all, ' => ', figures_all/purpose_len)\n",
    "print('screenshots: ', screenshots_all, ' => ', screenshots_all/purpose_len)\n",
    "print('blog: ', blog_all, ' => ', blog_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5418ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project reviews:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Project reviews\n",
    "\n",
    "project_review_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Project reviews'].iloc[i] == 'yes':\n",
    "        project_review_all += 1\n",
    "\n",
    "print('Project reviews: ', project_review_all, ' => ', project_review_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29894814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1107cb0",
   "metadata": {},
   "source": [
    "_**Miscellaneous**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "395b86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key case study characteristics summarized :  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "# Key case study characteristics summarized \n",
    "\n",
    "cs_charact_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Key case study characteristics summarized '].iloc[i] == 'yes':\n",
    "        cs_charact_all += 1\n",
    "\n",
    "print('Key case study characteristics summarized : ', cs_charact_all, ' => ', cs_charact_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e90752cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methodological literature cited:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "# Methodological literature cited\n",
    "\n",
    "methodol_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Methodological literature cited'].iloc[i] == 'yes':\n",
    "        methodol_all += 1\n",
    "\n",
    "print('Methodological literature cited: ', methodol_all, ' => ', methodol_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d30b48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other case studies cited:  2  =>  1.0\n"
     ]
    }
   ],
   "source": [
    "#Other case studies cited\n",
    "\n",
    "other_cs_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Other case studies cited'].iloc[i] == 'yes':\n",
    "        other_cs_all += 1\n",
    "\n",
    "print('Other case studies cited: ', other_cs_all, ' => ', other_cs_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e81544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online-Appendix:  0  =>  0.0\n"
     ]
    }
   ],
   "source": [
    "#Online-Appendix\n",
    "\n",
    "online_appendix_all = 0\n",
    "\n",
    "for i in range(0, purpose_len):\n",
    "    if df['Online-Appendix'].iloc[i] == 'yes':\n",
    "        online_appendix_all += 1\n",
    "\n",
    "print('Online-Appendix: ', online_appendix_all, ' => ', online_appendix_all/purpose_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7149084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
